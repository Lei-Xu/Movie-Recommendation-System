{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System based on Collaborative Filtering\n",
    "\n",
    "**Collaborative filtering** (CF) systems work by collecting user feedback in the form of ratings for items in a given domain and exploiting similarities in rating behavior among several users in determining how to recommend an item. The main advantage is that it requires no information about users or items and the more users interact with items the more new recommendations become accurate. However, as it only consider past interactions to make recommendations, collaborative filtering suffer from the **“cold start problem”**, which means that it is impossible to recommend anything to new users or to recommend a new item to any users and many users or items have too few interactions to be efficiently handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Datasets\n",
    "\n",
    "In the project, I am planning to use [MovieLens]{https://grouplens.org/datasets/movielens/} as the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import hashlib\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from os.path import isfile, isdir\n",
    "from urllib.request import urlretrieve\n",
    "from tensorflow.python.ops import math_ops\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unzip(save_path, _, database_name, data_path):\n",
    "    \"\"\"Unzip wrapper with the same interface as _ungzip\n",
    "    Args:\n",
    "        save_path: The path of the gzip files\n",
    "        database_name: Name of database\n",
    "        data_path: Path to extract to\n",
    "        _: HACK - Used to have to same interface as _ungzip\n",
    "    \"\"\"\n",
    "    print(f'Extracting { database_name }...')\n",
    "    with zipfile.ZipFile(save_path) as zf:\n",
    "        zf.extractall(data_path)\n",
    "\n",
    "def download_extract(database_name, data_path):\n",
    "    \"\"\"Download and extract database\n",
    "    Args:\n",
    "        database_name: Database name\n",
    "        data_path: Path to extract to\n",
    "    \"\"\"\n",
    "    DATASET_NAME = 'ml-1m'\n",
    "    if database_name == DATASET_NAME:\n",
    "        url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "        hash_code = 'c4d9eecfca2ab87c1945afe126590906'\n",
    "        extract_path = os.path.join(data_path, DATASET_NAME)\n",
    "        save_path = os.path.join(data_path, f'{ DATASET_NAME }.zip')\n",
    "        extract_fn = _unzip\n",
    "        \n",
    "    if os.path.exists(extract_path):\n",
    "        print(f'Found { database_name } Data')\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc=f'Downloading { database_name }') as pbar:\n",
    "            urlretrieve(url, save_path, pbar.hook)\n",
    "\n",
    "    assert hashlib.md5(open(save_path, 'rb').read()).hexdigest() == hash_code, \\\n",
    "        f'{ save_path } file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "    os.makedirs(extract_path)\n",
    "    try:\n",
    "        extract_fn(save_path, extract_path, database_name, data_path)\n",
    "    except Exception as err:\n",
    "        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\n",
    "        raise err\n",
    "\n",
    "    print('Done downloading and extracing')\n",
    "    \n",
    "class DLProgress(tqdm):\n",
    "    \"\"\"Handle Progress Bar while Downloading\"\"\"\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        \"\"\"\n",
    "        A hook function that will be called once on establishment of the network connection and\n",
    "        once after each block read thereafter.\n",
    "        Args:\n",
    "            block_num: A count of blocks transferred so far\n",
    "            block_size: Block size in bytes\n",
    "            total_size: The total size of the file. This may be -1 on older FTP servers which do not return\n",
    "                            a file size in response to a retrieval request.\n",
    "        \"\"\"\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading ml-1m: 5.92MB [00:06, 918kB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ml-1m...\n",
      "Done downloading and extracing\n"
     ]
    }
   ],
   "source": [
    "data_dir = './'\n",
    "download_extract('ml-1m', data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Dataset\n",
    "\n",
    "The movie dataset includes three parts: users'data - **users.dat**, movies'data - **movies.dat**, ratings'data - **ratings.dat**\n",
    "\n",
    "### Uses' Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>OccupationID</th>\n",
       "      <th>Zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  OccupationID Zip-code\n",
       "0       1      F    1            10    48067\n",
       "1       2      M   56            16    70072\n",
       "2       3      M   25            15    55117\n",
       "3       4      M   45             7    02460\n",
       "4       5      M   25            20    55455"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_title = ['UserID', 'Gender', 'Age', 'OccupationID', 'Zip-code']\n",
    "users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "users.head()\n",
    "# print(users.head)\n",
    "# print('-'*20)\n",
    "# age_map = {val:idx for idx, val in enumerate(set(users['Age']))}\n",
    "# print(age_map)\n",
    "# users['Age'] = users['Age'].map(age_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies' Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_title = ['MovieID', 'Title', 'Genres']\n",
    "movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings' Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  timestamps\n",
       "0       1     1193       5   978300760\n",
       "1       1      661       3   978302109\n",
       "2       1      914       3   978301968\n",
       "3       1     3408       4   978300275\n",
       "4       1     2355       5   978824291"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_title = ['UserID','MovieID', 'Rating', 'timestamps']\n",
    "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. Gender: change **F** to **0** and change **M** to **1**\n",
    "2. Age: transform to continous numbers from 0 to 7\n",
    "3. Genres: transform to digits\n",
    "4. Title: same as **Genres**\n",
    "\n",
    "Notes: The length of **Genres** and **Title** should be same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load dataset from file and then preprocessing it\"\"\"\n",
    "    # Load users' data\n",
    "    users_title = ['UserID', 'Gender', 'Age', 'JobID', 'Zip-code']\n",
    "    users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "    users = users.filter(regex='UserID|Gender|Age|JobID')\n",
    "    users_origin = users.values\n",
    "    # Preprocess users' gender and age attributes\n",
    "    gender_map = {'F':0, 'M':1}\n",
    "    users['Gender'] = users['Gender'].map(gender_map)\n",
    "    age_map = {val:idx for idx, val in enumerate(set(users['Age']))}\n",
    "    users['Age'] = users['Age'].map(age_map)\n",
    "    \n",
    "    # Load movies' data\n",
    "    movies_title = ['MovieID', 'Title', 'Genres']\n",
    "    movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "    movies_origin = movies.values\n",
    "    # Remove year from title\n",
    "    pattern = re.compile(r'^(.*)\\((\\d+)\\)$')\n",
    "    title_map = {title:pattern.match(title).group(1) for title in set(movies['Title'])}\n",
    "    movies['Title'] = movies['Title'].map(title_map)\n",
    "    # Change movies' genre to dict with numbers\n",
    "    genres_set = set()\n",
    "    for val in movies['Genres'].str.split('|'):\n",
    "        genres_set.update(val)\n",
    "    genres_set.add('<PAD>')\n",
    "    genres2int = {val:idx for idx, val in enumerate(genres_set)}\n",
    "    genres_map = {val:[genres2int[row] for row in val.split('|')] for val in set(movies['Genres'])}\n",
    "    for key in genres_map:\n",
    "        for cnt in range(max(genres2int.values()) - len(genres_map[key])):\n",
    "            genres_map[key].insert(len(genres_map[key]) + cnt, genres2int['<PAD>'])\n",
    "    movies['Genres'] = movies['Genres'].map(genres_map)\n",
    "\n",
    "    # Change movies' title to dict with numbers\n",
    "    title_set = set()\n",
    "    for val in movies['Title'].str.split():\n",
    "        title_set.update(val)\n",
    "    title_set.add('<PAD>')\n",
    "    title2int = {val:idx for idx, val in enumerate(title_set)}\n",
    "    title_count = 15\n",
    "    title_map = {val:[title2int[row] for row in val.split()] for val in set(movies['Title'])}\n",
    "    for key in title_map:\n",
    "        for cnt in range(title_count - len(title_map[key])):\n",
    "            title_map[key].insert(len(title_map[key]) + cnt, title2int['<PAD>'])\n",
    "    movies['Title'] = movies['Title'].map(title_map)\n",
    "\n",
    "    # Load ratings' data\n",
    "    ratings_title = ['UserID','MovieID', 'ratings', 'timestamps']\n",
    "    ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "    ratings = ratings.filter(regex='UserID|MovieID|ratings')\n",
    "\n",
    "    # Merge\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    \n",
    "    # Split data into two parts\n",
    "    target_fields = ['ratings']\n",
    "    features_pd, targets_pd = data.drop(target_fields, axis=1), data[target_fields]\n",
    "    features = features_pd.values\n",
    "    targets_values = targets_pd.values\n",
    "    \n",
    "    return title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin = load_data()\n",
    "pickle.dump((title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin), open('preprocess_movies.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(params):\n",
    "    \"\"\"Save parameters to file\"\"\"\n",
    "    pickle.dump(params, open('params.pkl', 'wb'))\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    \"\"\"Load parameters from file\"\"\"\n",
    "    return pickle.load(open('params.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of matrix\n",
    "embed_dim = 32\n",
    "# Number of users' ids\n",
    "uid_max = max(features.take(0,1)) + 1 # 6040\n",
    "# Number of genders\n",
    "gender_max = max(features.take(2,1)) + 1 # 1 + 1 = 2\n",
    "# Number of ages\n",
    "age_max = max(features.take(3,1)) + 1 # 6 + 1 = 7\n",
    "# Number of jobs\n",
    "job_max = max(features.take(4,1)) + 1# 20 + 1 = 21\n",
    "\n",
    "# Number of movies\n",
    "movie_id_max = max(features.take(1,1)) + 1 # 3952\n",
    "# Number of genres\n",
    "movie_categories_max = max(genres2int.values()) + 1 # 18 + 1 = 19\n",
    "# Number of words of movies' names\n",
    "movie_title_max = len(title_set) # 5216\n",
    "\n",
    "combiner = \"sum\"\n",
    "\n",
    "# Length of movies' name\n",
    "sentences_size = title_count # = 15\n",
    "\n",
    "window_sizes = {2, 3, 4, 5}\n",
    "filter_num = 8\n",
    "movieid2idx = {val[0]:idx for idx, val in enumerate(movies.values)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 5\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "\n",
    "dropout_keep = 0.5\n",
    "# Learning Rate\n",
    "learning_rate = 0.0001\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 20\n",
    "\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    uid = tf.keras.layers.Input(shape=(1,), dtype='int32', name='uid')  \n",
    "    user_gender = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_gender')  \n",
    "    user_age = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_age') \n",
    "    user_job = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_job')\n",
    "\n",
    "    movie_id = tf.keras.layers.Input(shape=(1,), dtype='int32', name='movie_id') \n",
    "    movie_categories = tf.keras.layers.Input(shape=(18,), dtype='int32', name='movie_categories') \n",
    "    movie_titles = tf.keras.layers.Input(shape=(15,), dtype='int32', name='movie_titles') \n",
    "    return uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network\n",
    "\n",
    "#### Define User's Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding(uid, user_gender, user_age, user_job):\n",
    "    uid_embed_layer = tf.keras.layers.Embedding(uid_max, embed_dim, input_length=1, name='uid_embed_layer')(uid)\n",
    "    gender_embed_layer = tf.keras.layers.Embedding(gender_max, embed_dim // 2, input_length=1, name='gender_embed_layer')(user_gender)\n",
    "    age_embed_layer = tf.keras.layers.Embedding(age_max, embed_dim // 2, input_length=1, name='age_embed_layer')(user_age)\n",
    "    job_embed_layer = tf.keras.layers.Embedding(job_max, embed_dim // 2, input_length=1, name='job_embed_layer')(user_job)\n",
    "    return uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define User's Feature\n",
    "\n",
    "It is based on two fully connected layers, **1x128** and **1x200**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feature_layer(uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer):\n",
    "    # First FCL\n",
    "    uid_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"uid_fc_layer\", activation='relu')(uid_embed_layer)\n",
    "    gender_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"gender_fc_layer\", activation='relu')(gender_embed_layer)\n",
    "    age_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"age_fc_layer\", activation='relu')(age_embed_layer)\n",
    "    job_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"job_fc_layer\", activation='relu')(job_embed_layer)\n",
    "\n",
    "    # Second FCL\n",
    "    user_combine_layer = tf.keras.layers.concatenate([uid_fc_layer, gender_fc_layer, age_fc_layer, job_fc_layer], 2)  #(?, 1, 128)\n",
    "    user_combine_layer = tf.keras.layers.Dense(200, activation='tanh')(user_combine_layer)  #(?, 1, 200)\n",
    "\n",
    "    user_combine_layer_flat = tf.keras.layers.Reshape([200], name=\"user_combine_layer_flat\")(user_combine_layer)\n",
    "    return user_combine_layer, user_combine_layer_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Movie's ID Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_id_embed_layer(movie_id):\n",
    "    movie_id_embed_layer = tf.keras.layers.Embedding(movie_id_max, embed_dim, input_length=1, name='movie_id_embed_layer')(movie_id)\n",
    "    return movie_id_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Movie's Genre Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_categories_layers(movie_categories):\n",
    "    movie_categories_embed_layer = tf.keras.layers.Embedding(movie_categories_max, embed_dim, input_length=18, name='movie_categories_embed_layer')(movie_categories)\n",
    "    movie_categories_embed_layer = tf.keras.layers.Lambda(lambda layer: tf.reduce_sum(layer, axis=1, keepdims=True))(movie_categories_embed_layer)\n",
    "    return movie_categories_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define CNN of Movie's Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_cnn_layer(movie_titles):\n",
    "    movie_title_embed_layer = tf.keras.layers.Embedding(movie_title_max, embed_dim, input_length=15, name='movie_title_embed_layer')(movie_titles)\n",
    "    sp = movie_title_embed_layer.shape\n",
    "    movie_title_embed_layer_expand = tf.keras.layers.Reshape([sp[1], sp[2], 1])(movie_title_embed_layer)\n",
    "    pool_layer_lst = []\n",
    "    for window_size in window_sizes:\n",
    "        conv_layer = tf.keras.layers.Conv2D(filter_num, (window_size, embed_dim), 1, activation='relu')(movie_title_embed_layer_expand)\n",
    "        maxpool_layer = tf.keras.layers.MaxPooling2D(pool_size=(sentences_size - window_size + 1 ,1), strides=1)(conv_layer)\n",
    "        pool_layer_lst.append(maxpool_layer)\n",
    "    pool_layer = tf.keras.layers.concatenate(pool_layer_lst, 3, name =\"pool_layer\")  \n",
    "    max_num = len(window_sizes) * filter_num\n",
    "    pool_layer_flat = tf.keras.layers.Reshape([1, max_num], name = \"pool_layer_flat\")(pool_layer)\n",
    "\n",
    "    dropout_layer = tf.keras.layers.Dropout(dropout_keep, name = \"dropout_layer\")(pool_layer_flat)\n",
    "    return pool_layer_flat, dropout_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Movie's Feature\n",
    "\n",
    "It is based on two fully connected layers, **1x64** and **1x200**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_feature_layer(movie_id_embed_layer, movie_categories_embed_layer, dropout_layer):\n",
    "    # First FCL 64\n",
    "    movie_id_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"movie_id_fc_layer\", activation='relu')(movie_id_embed_layer)\n",
    "    movie_categories_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"movie_categories_fc_layer\", activation='relu')(movie_categories_embed_layer)\n",
    "\n",
    "    # Second FCL 200\n",
    "    movie_combine_layer = tf.keras.layers.concatenate([movie_id_fc_layer, movie_categories_fc_layer, dropout_layer], 2)  \n",
    "    movie_combine_layer = tf.keras.layers.Dense(200, activation='tanh')(movie_combine_layer)\n",
    "\n",
    "    movie_combine_layer_flat = tf.keras.layers.Reshape([200], name=\"movie_combine_layer_flat\")(movie_combine_layer)\n",
    "    return movie_combine_layer, movie_combine_layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_core.keras.layers' from '/Users/xulei/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/keras/api/_v2/keras/layers/__init__.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Computing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.ops import summary_ops_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mrs_network():\n",
    "    def __init__(self, batch_size=256):\n",
    "        self.batch_size = batch_size\n",
    "        self.best_loss = 9999\n",
    "        self.losses = {'train': [], 'test': []}\n",
    "        \n",
    "        # User's input\n",
    "        uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles = get_inputs()\n",
    "        \n",
    "        # User's embedding layers\n",
    "        uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer = get_user_embedding(uid, \n",
    "                                                                                                   user_gender,\n",
    "                                                                                                   user_age,\n",
    "                                                                                                   user_job)\n",
    "        # User's feature\n",
    "        user_combine_layer, user_combine_layer_flat = get_user_feature_layer(uid_embed_layer, \n",
    "                                                                             gender_embed_layer, \n",
    "                                                                             age_embed_layer, \n",
    "                                                                             job_embed_layer)\n",
    "        \n",
    "        # Movie's id embedding layer\n",
    "        movie_id_embed_layer = get_movie_id_embed_layer(movie_id)\n",
    "        # Movie's genre embedding layer\n",
    "        movie_categories_embed_layer = get_movie_categories_layers(movie_categories)\n",
    "        # Movie's name layer\n",
    "        pool_layer_flat, dropout_layer = get_movie_cnn_layer(movie_titles)\n",
    "        # Movie's feature\n",
    "        movie_combine_layer, movie_combine_layer_flat = get_movie_feature_layer(movie_id_embed_layer,\n",
    "                                                                                movie_categories_embed_layer,\n",
    "                                                                                dropout_layer)\n",
    "        # Combine user's feature and movie's feature to get rating prediction\n",
    "        inference = tf.keras.layers.Lambda(lambda layer: \n",
    "            tf.reduce_sum(layer[0] * layer[1], axis=1), name=\"inference\")((user_combine_layer_flat, movie_combine_layer_flat))\n",
    "        inference = tf.keras.layers.Lambda(lambda layer: tf.expand_dims(layer, axis=1))(inference)\n",
    "        \n",
    "        self.model = tf.keras.Model(\n",
    "            inputs=[uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles],\n",
    "            outputs=[inference])\n",
    "\n",
    "        self.model.summary()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        # MSE Loss\n",
    "        self.ComputeLoss = tf.keras.losses.MeanSquaredError()\n",
    "        self.ComputeMetrics = tf.keras.metrics.MeanAbsoluteError()\n",
    "        \n",
    "        if tf.io.gfile.exists(MODEL_DIR):\n",
    "            pass\n",
    "        else:\n",
    "            tf.io.gfile.makedirs(MODEL_DIR)\n",
    "\n",
    "        train_dir = os.path.join(MODEL_DIR, 'summaries', 'train')\n",
    "        test_dir = os.path.join(MODEL_DIR, 'summaries', 'eval')\n",
    "\n",
    "        checkpoint_dir = os.path.join(MODEL_DIR, 'checkpoints')\n",
    "        self.checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "        self.checkpoint = tf.train.Checkpoint(model=self.model, optimizer=self.optimizer)\n",
    "\n",
    "        # Restore variables on creation if a checkpoint exists.\n",
    "        self.checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    def compute_loss(self, labels, logits):\n",
    "        return tf.reduce_mean(tf.keras.losses.mse(labels, logits))\n",
    "\n",
    "    def compute_metrics(self, labels, logits):\n",
    "        return tf.keras.metrics.mae(labels, logits)\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model([x[0],\n",
    "                                 x[1],\n",
    "                                 x[2],\n",
    "                                 x[3],\n",
    "                                 x[4],\n",
    "                                 x[5],\n",
    "                                 x[6]], training=True)\n",
    "            loss = self.ComputeLoss(y, logits)\n",
    "            self.ComputeMetrics(y, logits)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        return loss, logits\n",
    "    \n",
    "    def training(self, features, targets_values, epochs=5, log_freq=50):\n",
    "        for epoch_i in range(epochs):\n",
    "            # separate the dataset into training and testing\n",
    "            train_X, test_X, train_y, test_y = train_test_split(features,\n",
    "                                                                targets_values,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "            train_batches = get_batches(train_X, train_y, self.batch_size)\n",
    "            batch_num = (len(train_X) // self.batch_size)\n",
    "            train_start = time.time()\n",
    "            \n",
    "            if True:\n",
    "                start = time.time()\n",
    "                avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "                for batch_i in range(batch_num):\n",
    "                    x, y = next(train_batches)\n",
    "                    categories = np.zeros([self.batch_size, 18])\n",
    "                    for i in range(self.batch_size):\n",
    "                        categories[i] = x.take(6, 1)[i]\n",
    "\n",
    "                    titles = np.zeros([self.batch_size, sentences_size])\n",
    "                    for i in range(self.batch_size):\n",
    "                        titles[i] = x.take(5, 1)[i]\n",
    "\n",
    "                    loss, logits = self.train_step([np.reshape(x.take(0, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    np.reshape(x.take(2, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    np.reshape(x.take(3, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    np.reshape(x.take(4, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    np.reshape(x.take(1, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    categories.astype(np.float32),\n",
    "                                                    titles.astype(np.float32)],\n",
    "                                                   np.reshape(y, [self.batch_size, 1]).astype(np.float32))\n",
    "                    avg_loss(loss)\n",
    "                    self.losses['train'].append(loss)\n",
    "\n",
    "                    if tf.equal(self.optimizer.iterations % log_freq, 0):\n",
    "                        rate = log_freq / (time.time() - start)\n",
    "                        print('Step #{}\\tEpoch {:>3} Batch {:>4}/{}   Loss: {:0.6f} mae: {:0.6f} ({} steps/sec)'.format(\n",
    "                            self.optimizer.iterations.numpy(),\n",
    "                            epoch_i,\n",
    "                            batch_i,\n",
    "                            batch_num,\n",
    "                            loss, (self.ComputeMetrics.result()), rate))\n",
    "                        avg_loss.reset_states()\n",
    "                        self.ComputeMetrics.reset_states()\n",
    "                        start = time.time()\n",
    "\n",
    "            train_end = time.time()\n",
    "            print('\\nTrain time for epoch #{} ({} total steps): {}'.format(epoch_i + 1, \n",
    "                                                                           self.optimizer.iterations.numpy(),\n",
    "                                                                           train_end - train_start))\n",
    "            self.testing((test_X, test_y), self.optimizer.iterations)\n",
    "        self.export_path = os.path.join(MODEL_DIR, 'export')\n",
    "        tf.saved_model.save(self.model, self.export_path)\n",
    "    \n",
    "    def testing(self, test_dataset, step_num):\n",
    "        test_X, test_y = test_dataset\n",
    "        test_batches = get_batches(test_X, test_y, self.batch_size)\n",
    "\n",
    "        avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "        batch_num = (len(test_X) // self.batch_size)\n",
    "        for batch_i in range(batch_num):\n",
    "            x, y = next(test_batches)\n",
    "            categories = np.zeros([self.batch_size, 18])\n",
    "            for i in range(self.batch_size):\n",
    "                categories[i] = x.take(6, 1)[i]\n",
    "\n",
    "            titles = np.zeros([self.batch_size, sentences_size])\n",
    "            for i in range(self.batch_size):\n",
    "                titles[i] = x.take(5, 1)[i]\n",
    "\n",
    "            logits = self.model([np.reshape(x.take(0, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 np.reshape(x.take(2, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 np.reshape(x.take(3, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 np.reshape(x.take(4, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 np.reshape(x.take(1, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 categories.astype(np.float32),\n",
    "                                 titles.astype(np.float32)], training=False)\n",
    "            test_loss = self.ComputeLoss(np.reshape(y, [self.batch_size, 1]).astype(np.float32), logits)\n",
    "            avg_loss(test_loss)\n",
    "            # Save testing loss\n",
    "            self.losses['test'].append(test_loss)\n",
    "            self.ComputeMetrics(np.reshape(y, [self.batch_size, 1]).astype(np.float32), logits)\n",
    "\n",
    "        print('Model test set loss: {:0.6f} mae: {:0.6f}'.format(avg_loss.result(), \n",
    "                                                                 self.ComputeMetrics.result()))\n",
    "\n",
    "        if avg_loss.result() < self.best_loss:\n",
    "            self.best_loss = avg_loss.result()\n",
    "            print(f'best loss = { self.best_loss }')\n",
    "            self.checkpoint.save(self.checkpoint_prefix)\n",
    "\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        predictions = self.model(xs)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(Xs, ys, batch_size):\n",
    "    for start in range(0, len(Xs), batch_size):\n",
    "        end = min(start + batch_size, len(Xs))\n",
    "        yield Xs[start:end], ys[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network\n",
    "\n",
    "Input the user's feature and movie's feature, output the training result through the fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "movie_titles (InputLayer)       [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_title_embed_layer (Embedd (None, 15, 32)       166880      movie_titles[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 15, 32, 1)    0           movie_title_embed_layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 14, 1, 8)     520         reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 13, 1, 8)     776         reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 12, 1, 8)     1032        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 11, 1, 8)     1288        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "movie_categories (InputLayer)   [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 1, 1, 8)      0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 1, 1, 8)      0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 1, 1, 8)      0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 1, 1, 8)      0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "uid (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_gender (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_age (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_job (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_categories_embed_layer (E (None, 18, 32)       608         movie_categories[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool_layer (Concatenate)        (None, 1, 1, 32)     0           max_pooling2d_20[0][0]           \n",
      "                                                                 max_pooling2d_21[0][0]           \n",
      "                                                                 max_pooling2d_22[0][0]           \n",
      "                                                                 max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "uid_embed_layer (Embedding)     (None, 1, 32)        193312      uid[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gender_embed_layer (Embedding)  (None, 1, 16)        32          user_gender[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "age_embed_layer (Embedding)     (None, 1, 16)        112         user_age[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "job_embed_layer (Embedding)     (None, 1, 16)        336         user_job[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "movie_id_embed_layer (Embedding (None, 1, 32)        126496      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 32)        0           movie_categories_embed_layer[0][0\n",
      "__________________________________________________________________________________________________\n",
      "pool_layer_flat (Reshape)       (None, 1, 32)        0           pool_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "uid_fc_layer (Dense)            (None, 1, 32)        1056        uid_embed_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gender_fc_layer (Dense)         (None, 1, 32)        544         gender_embed_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "age_fc_layer (Dense)            (None, 1, 32)        544         age_embed_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "job_fc_layer (Dense)            (None, 1, 32)        544         job_embed_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id_fc_layer (Dense)       (None, 1, 32)        1056        movie_id_embed_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "movie_categories_fc_layer (Dens (None, 1, 32)        1056        lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_layer (Dropout)         (None, 1, 32)        0           pool_layer_flat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 1, 128)       0           uid_fc_layer[0][0]               \n",
      "                                                                 gender_fc_layer[0][0]            \n",
      "                                                                 age_fc_layer[0][0]               \n",
      "                                                                 job_fc_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 1, 96)        0           movie_id_fc_layer[0][0]          \n",
      "                                                                 movie_categories_fc_layer[0][0]  \n",
      "                                                                 dropout_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 200)       25800       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 200)       19400       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "user_combine_layer_flat (Reshap (None, 200)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "movie_combine_layer_flat (Resha (None, 200)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "inference (Lambda)              (None,)              0           user_combine_layer_flat[0][0]    \n",
      "                                                                 movie_combine_layer_flat[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           inference[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 541,392\n",
      "Trainable params: 541,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Step #50\tEpoch   0 Batch   49/3125   Loss: 10.144194 mae: 3.333478 (9.005710245677035 steps/sec)\n",
      "Step #100\tEpoch   0 Batch   99/3125   Loss: 1.840343 mae: 2.032882 (23.53775161514289 steps/sec)\n",
      "Step #150\tEpoch   0 Batch  149/3125   Loss: 1.241449 mae: 0.945408 (22.554576074609475 steps/sec)\n",
      "Step #200\tEpoch   0 Batch  199/3125   Loss: 1.275179 mae: 0.926247 (24.456075430737414 steps/sec)\n",
      "Step #250\tEpoch   0 Batch  249/3125   Loss: 1.143847 mae: 0.911200 (23.503442438783406 steps/sec)\n",
      "Step #300\tEpoch   0 Batch  299/3125   Loss: 1.373467 mae: 0.909951 (22.526712413596126 steps/sec)\n",
      "Step #350\tEpoch   0 Batch  349/3125   Loss: 1.196895 mae: 0.905331 (21.05673449884337 steps/sec)\n",
      "Step #400\tEpoch   0 Batch  399/3125   Loss: 1.331487 mae: 0.899384 (22.22956205106853 steps/sec)\n",
      "Step #450\tEpoch   0 Batch  449/3125   Loss: 1.137105 mae: 0.895732 (23.096179087369475 steps/sec)\n",
      "Step #500\tEpoch   0 Batch  499/3125   Loss: 1.035245 mae: 0.879842 (22.443465721990457 steps/sec)\n",
      "Step #550\tEpoch   0 Batch  549/3125   Loss: 1.068681 mae: 0.867137 (22.133763944738202 steps/sec)\n",
      "Step #600\tEpoch   0 Batch  599/3125   Loss: 0.930701 mae: 0.865216 (22.79228387672018 steps/sec)\n",
      "Step #650\tEpoch   0 Batch  649/3125   Loss: 1.066496 mae: 0.848791 (22.890714094855213 steps/sec)\n",
      "Step #700\tEpoch   0 Batch  699/3125   Loss: 0.928253 mae: 0.832026 (22.382900660637276 steps/sec)\n",
      "Step #750\tEpoch   0 Batch  749/3125   Loss: 0.931109 mae: 0.815082 (20.21628410178243 steps/sec)\n",
      "Step #800\tEpoch   0 Batch  799/3125   Loss: 1.051691 mae: 0.803828 (21.484417498952492 steps/sec)\n",
      "Step #850\tEpoch   0 Batch  849/3125   Loss: 1.063254 mae: 0.799307 (22.404285243462017 steps/sec)\n",
      "Step #900\tEpoch   0 Batch  899/3125   Loss: 0.958729 mae: 0.781695 (21.637828808995568 steps/sec)\n",
      "Step #950\tEpoch   0 Batch  949/3125   Loss: 0.807645 mae: 0.774171 (21.621331831118813 steps/sec)\n",
      "Step #1000\tEpoch   0 Batch  999/3125   Loss: 0.990058 mae: 0.772309 (21.800512841463338 steps/sec)\n",
      "Step #1050\tEpoch   0 Batch 1049/3125   Loss: 0.951738 mae: 0.771160 (21.34074476141515 steps/sec)\n",
      "Step #1100\tEpoch   0 Batch 1099/3125   Loss: 0.876033 mae: 0.762140 (21.05273724976213 steps/sec)\n",
      "Step #1150\tEpoch   0 Batch 1149/3125   Loss: 0.852533 mae: 0.764763 (20.92043439125998 steps/sec)\n",
      "Step #1200\tEpoch   0 Batch 1199/3125   Loss: 0.817208 mae: 0.750696 (21.391983718381532 steps/sec)\n",
      "Step #1250\tEpoch   0 Batch 1249/3125   Loss: 0.976251 mae: 0.757223 (20.75498325965205 steps/sec)\n",
      "Step #1300\tEpoch   0 Batch 1299/3125   Loss: 0.905333 mae: 0.761073 (20.882992816850805 steps/sec)\n",
      "Step #1350\tEpoch   0 Batch 1349/3125   Loss: 0.924585 mae: 0.739378 (20.666050967440075 steps/sec)\n",
      "Step #1400\tEpoch   0 Batch 1399/3125   Loss: 0.866819 mae: 0.747909 (21.064276541751603 steps/sec)\n",
      "Step #1450\tEpoch   0 Batch 1449/3125   Loss: 0.867059 mae: 0.747742 (20.807168338726072 steps/sec)\n",
      "Step #1500\tEpoch   0 Batch 1499/3125   Loss: 0.905172 mae: 0.745656 (20.57423562492973 steps/sec)\n",
      "Step #1550\tEpoch   0 Batch 1549/3125   Loss: 0.909089 mae: 0.743876 (20.373459144168837 steps/sec)\n",
      "Step #1600\tEpoch   0 Batch 1599/3125   Loss: 0.873809 mae: 0.742451 (20.822522359007884 steps/sec)\n",
      "Step #1650\tEpoch   0 Batch 1649/3125   Loss: 0.922004 mae: 0.740780 (20.55985213665301 steps/sec)\n",
      "Step #1700\tEpoch   0 Batch 1699/3125   Loss: 0.915286 mae: 0.732805 (20.84284254299233 steps/sec)\n",
      "Step #1750\tEpoch   0 Batch 1749/3125   Loss: 0.887780 mae: 0.736458 (20.268181667062272 steps/sec)\n",
      "Step #1800\tEpoch   0 Batch 1799/3125   Loss: 0.977101 mae: 0.740207 (19.517246988912735 steps/sec)\n",
      "Step #1850\tEpoch   0 Batch 1849/3125   Loss: 0.789450 mae: 0.738525 (20.138406217812815 steps/sec)\n",
      "Step #1900\tEpoch   0 Batch 1899/3125   Loss: 0.894145 mae: 0.734832 (19.76412002557746 steps/sec)\n",
      "Step #1950\tEpoch   0 Batch 1949/3125   Loss: 0.868240 mae: 0.729912 (19.443856988512266 steps/sec)\n",
      "Step #2000\tEpoch   0 Batch 1999/3125   Loss: 0.949070 mae: 0.738616 (20.233600586606464 steps/sec)\n",
      "Step #2050\tEpoch   0 Batch 2049/3125   Loss: 0.830388 mae: 0.742345 (18.341744823336846 steps/sec)\n",
      "Step #2100\tEpoch   0 Batch 2099/3125   Loss: 0.881472 mae: 0.725401 (18.92094550233364 steps/sec)\n",
      "Step #2150\tEpoch   0 Batch 2149/3125   Loss: 0.801960 mae: 0.725420 (19.24821216619117 steps/sec)\n",
      "Step #2200\tEpoch   0 Batch 2199/3125   Loss: 0.775626 mae: 0.726574 (15.845264713475743 steps/sec)\n",
      "Step #2250\tEpoch   0 Batch 2249/3125   Loss: 0.824368 mae: 0.728481 (17.419374987956 steps/sec)\n",
      "Step #2300\tEpoch   0 Batch 2299/3125   Loss: 0.879827 mae: 0.737500 (15.858164332363335 steps/sec)\n",
      "Step #2350\tEpoch   0 Batch 2349/3125   Loss: 0.846280 mae: 0.731400 (14.894663934826754 steps/sec)\n",
      "Step #2400\tEpoch   0 Batch 2399/3125   Loss: 0.782127 mae: 0.733447 (16.67201425628172 steps/sec)\n",
      "Step #2450\tEpoch   0 Batch 2449/3125   Loss: 0.858018 mae: 0.724283 (17.51598269776863 steps/sec)\n",
      "Step #2500\tEpoch   0 Batch 2499/3125   Loss: 0.932844 mae: 0.731521 (17.646912308691714 steps/sec)\n",
      "Step #2550\tEpoch   0 Batch 2549/3125   Loss: 0.683993 mae: 0.736131 (14.814427599150221 steps/sec)\n",
      "Step #2600\tEpoch   0 Batch 2599/3125   Loss: 1.011743 mae: 0.732526 (14.933900737704013 steps/sec)\n",
      "Step #2650\tEpoch   0 Batch 2649/3125   Loss: 0.909488 mae: 0.729066 (16.654364084071997 steps/sec)\n",
      "Step #2700\tEpoch   0 Batch 2699/3125   Loss: 0.802632 mae: 0.728252 (14.158233833997997 steps/sec)\n",
      "Step #2750\tEpoch   0 Batch 2749/3125   Loss: 1.008617 mae: 0.725468 (14.891665482591684 steps/sec)\n",
      "Step #2800\tEpoch   0 Batch 2799/3125   Loss: 0.848304 mae: 0.730210 (15.036310739657585 steps/sec)\n",
      "Step #2850\tEpoch   0 Batch 2849/3125   Loss: 0.833001 mae: 0.724567 (12.945799059340118 steps/sec)\n",
      "Step #2900\tEpoch   0 Batch 2899/3125   Loss: 0.875811 mae: 0.724126 (15.206469234727724 steps/sec)\n",
      "Step #2950\tEpoch   0 Batch 2949/3125   Loss: 0.891891 mae: 0.728514 (15.658503605040075 steps/sec)\n",
      "Step #3000\tEpoch   0 Batch 2999/3125   Loss: 0.767142 mae: 0.724311 (15.026535640760418 steps/sec)\n",
      "Step #3050\tEpoch   0 Batch 3049/3125   Loss: 0.809148 mae: 0.716084 (16.27817659136557 steps/sec)\n",
      "Step #3100\tEpoch   0 Batch 3099/3125   Loss: 0.893842 mae: 0.721982 (16.502941079956976 steps/sec)\n",
      "\n",
      "Train time for epoch #1 (3125 total steps): 167.35611391067505\n",
      "Model test set loss: 0.844176 mae: 0.728804\n",
      "best loss = 0.8441755771636963\n",
      "Step #3150\tEpoch   1 Batch   24/3125   Loss: 0.743703 mae: 0.728679 (41.741836002102666 steps/sec)\n",
      "Step #3200\tEpoch   1 Batch   74/3125   Loss: 0.899290 mae: 0.721825 (18.9962741196472 steps/sec)\n",
      "Step #3250\tEpoch   1 Batch  124/3125   Loss: 0.727150 mae: 0.728398 (17.475756957088752 steps/sec)\n",
      "Step #3300\tEpoch   1 Batch  174/3125   Loss: 0.756215 mae: 0.725539 (17.505287515819976 steps/sec)\n",
      "Step #3350\tEpoch   1 Batch  224/3125   Loss: 0.615337 mae: 0.721962 (17.280021779324326 steps/sec)\n",
      "Step #3400\tEpoch   1 Batch  274/3125   Loss: 0.851654 mae: 0.721521 (17.58476761363741 steps/sec)\n",
      "Step #3450\tEpoch   1 Batch  324/3125   Loss: 0.814592 mae: 0.725018 (17.197987464666518 steps/sec)\n",
      "Step #3500\tEpoch   1 Batch  374/3125   Loss: 0.824568 mae: 0.726463 (17.457643725222784 steps/sec)\n",
      "Step #3550\tEpoch   1 Batch  424/3125   Loss: 0.880402 mae: 0.727606 (16.891205965634967 steps/sec)\n",
      "Step #3600\tEpoch   1 Batch  474/3125   Loss: 0.803164 mae: 0.722747 (16.64325642621616 steps/sec)\n",
      "Step #3650\tEpoch   1 Batch  524/3125   Loss: 0.838173 mae: 0.717421 (16.241892324445963 steps/sec)\n",
      "Step #3700\tEpoch   1 Batch  574/3125   Loss: 0.906566 mae: 0.728661 (17.159363256210163 steps/sec)\n",
      "Step #3750\tEpoch   1 Batch  624/3125   Loss: 0.661812 mae: 0.722225 (16.425766360761227 steps/sec)\n",
      "Step #3800\tEpoch   1 Batch  674/3125   Loss: 0.845650 mae: 0.724191 (16.029772092576728 steps/sec)\n",
      "Step #3850\tEpoch   1 Batch  724/3125   Loss: 0.672600 mae: 0.722609 (15.733229383011023 steps/sec)\n",
      "Step #3900\tEpoch   1 Batch  774/3125   Loss: 0.779980 mae: 0.715583 (16.14463683936019 steps/sec)\n",
      "Step #3950\tEpoch   1 Batch  824/3125   Loss: 0.867452 mae: 0.721328 (15.67457017830568 steps/sec)\n",
      "Step #4000\tEpoch   1 Batch  874/3125   Loss: 0.791723 mae: 0.721128 (15.424129886914093 steps/sec)\n",
      "Step #4050\tEpoch   1 Batch  924/3125   Loss: 0.943577 mae: 0.726362 (15.377471225058608 steps/sec)\n",
      "Step #4100\tEpoch   1 Batch  974/3125   Loss: 0.756046 mae: 0.723013 (15.938875763682441 steps/sec)\n",
      "Step #4150\tEpoch   1 Batch 1024/3125   Loss: 0.833900 mae: 0.721028 (15.235958615248368 steps/sec)\n",
      "Step #4200\tEpoch   1 Batch 1074/3125   Loss: 0.850589 mae: 0.720315 (13.620634057235641 steps/sec)\n",
      "Step #4250\tEpoch   1 Batch 1124/3125   Loss: 0.852442 mae: 0.724320 (14.794264925410776 steps/sec)\n",
      "Step #4300\tEpoch   1 Batch 1174/3125   Loss: 0.772379 mae: 0.725228 (14.004601750882403 steps/sec)\n",
      "Step #4350\tEpoch   1 Batch 1224/3125   Loss: 0.770114 mae: 0.716526 (14.181202754727199 steps/sec)\n",
      "Step #4400\tEpoch   1 Batch 1274/3125   Loss: 0.951782 mae: 0.733627 (14.318072207556991 steps/sec)\n",
      "Step #4450\tEpoch   1 Batch 1324/3125   Loss: 0.794991 mae: 0.719249 (15.057021193249573 steps/sec)\n",
      "Step #4500\tEpoch   1 Batch 1374/3125   Loss: 0.801518 mae: 0.716666 (16.60348510157002 steps/sec)\n",
      "Step #4550\tEpoch   1 Batch 1424/3125   Loss: 0.826247 mae: 0.720650 (16.75835011976917 steps/sec)\n",
      "Step #4600\tEpoch   1 Batch 1474/3125   Loss: 0.729730 mae: 0.721437 (16.786475419841583 steps/sec)\n",
      "Step #4650\tEpoch   1 Batch 1524/3125   Loss: 0.739431 mae: 0.717516 (17.334099604254078 steps/sec)\n",
      "Step #4700\tEpoch   1 Batch 1574/3125   Loss: 0.796219 mae: 0.725933 (17.318902786225326 steps/sec)\n",
      "Step #4750\tEpoch   1 Batch 1624/3125   Loss: 0.893675 mae: 0.714170 (17.706167978238106 steps/sec)\n",
      "Step #4800\tEpoch   1 Batch 1674/3125   Loss: 0.789209 mae: 0.720840 (18.010322249758183 steps/sec)\n",
      "Step #4850\tEpoch   1 Batch 1724/3125   Loss: 0.926829 mae: 0.718370 (17.953546745609746 steps/sec)\n",
      "Step #4900\tEpoch   1 Batch 1774/3125   Loss: 0.763115 mae: 0.719182 (17.710294931464777 steps/sec)\n",
      "Step #4950\tEpoch   1 Batch 1824/3125   Loss: 0.736126 mae: 0.722028 (17.4993439264697 steps/sec)\n",
      "Step #5000\tEpoch   1 Batch 1874/3125   Loss: 0.904662 mae: 0.720718 (17.767504192259437 steps/sec)\n",
      "Step #5050\tEpoch   1 Batch 1924/3125   Loss: 1.009034 mae: 0.717179 (18.45354162648304 steps/sec)\n",
      "Step #5100\tEpoch   1 Batch 1974/3125   Loss: 0.832976 mae: 0.715312 (16.55854517707516 steps/sec)\n",
      "Step #5150\tEpoch   1 Batch 2024/3125   Loss: 0.866341 mae: 0.725052 (16.786363896869236 steps/sec)\n",
      "Step #5200\tEpoch   1 Batch 2074/3125   Loss: 0.885883 mae: 0.714846 (16.93979192625804 steps/sec)\n",
      "Step #5250\tEpoch   1 Batch 2124/3125   Loss: 0.670449 mae: 0.718591 (17.135798345310093 steps/sec)\n",
      "Step #5300\tEpoch   1 Batch 2174/3125   Loss: 0.744176 mae: 0.710802 (16.61007611251327 steps/sec)\n",
      "Step #5350\tEpoch   1 Batch 2224/3125   Loss: 0.725832 mae: 0.717056 (16.936267878904367 steps/sec)\n",
      "Step #5400\tEpoch   1 Batch 2274/3125   Loss: 0.846023 mae: 0.717436 (17.104662179268008 steps/sec)\n",
      "Step #5450\tEpoch   1 Batch 2324/3125   Loss: 0.686363 mae: 0.725906 (16.816723191459232 steps/sec)\n",
      "Step #5500\tEpoch   1 Batch 2374/3125   Loss: 0.778101 mae: 0.716248 (16.373965829065376 steps/sec)\n",
      "Step #5550\tEpoch   1 Batch 2424/3125   Loss: 0.788073 mae: 0.719565 (16.862212342019678 steps/sec)\n",
      "Step #5600\tEpoch   1 Batch 2474/3125   Loss: 0.888343 mae: 0.712953 (16.222294144184005 steps/sec)\n",
      "Step #5650\tEpoch   1 Batch 2524/3125   Loss: 0.796208 mae: 0.722521 (16.649506294954676 steps/sec)\n",
      "Step #5700\tEpoch   1 Batch 2574/3125   Loss: 0.898985 mae: 0.723855 (15.945389668105982 steps/sec)\n",
      "Step #5750\tEpoch   1 Batch 2624/3125   Loss: 0.969489 mae: 0.722365 (15.993934185269548 steps/sec)\n",
      "Step #5800\tEpoch   1 Batch 2674/3125   Loss: 0.835466 mae: 0.719618 (16.41328874439146 steps/sec)\n",
      "Step #5850\tEpoch   1 Batch 2724/3125   Loss: 0.798723 mae: 0.711416 (16.468995456237426 steps/sec)\n",
      "Step #5900\tEpoch   1 Batch 2774/3125   Loss: 0.777299 mae: 0.718158 (15.126931871058636 steps/sec)\n",
      "Step #5950\tEpoch   1 Batch 2824/3125   Loss: 0.856636 mae: 0.725582 (15.299447282779463 steps/sec)\n",
      "Step #6000\tEpoch   1 Batch 2874/3125   Loss: 0.861801 mae: 0.708879 (13.83911443478013 steps/sec)\n",
      "Step #6050\tEpoch   1 Batch 2924/3125   Loss: 0.837498 mae: 0.715767 (14.771995594221208 steps/sec)\n",
      "Step #6100\tEpoch   1 Batch 2974/3125   Loss: 0.749216 mae: 0.718879 (14.808004865881115 steps/sec)\n",
      "Step #6150\tEpoch   1 Batch 3024/3125   Loss: 0.715374 mae: 0.709986 (15.025551617017637 steps/sec)\n",
      "Step #6200\tEpoch   1 Batch 3074/3125   Loss: 0.834816 mae: 0.709813 (16.78088765821962 steps/sec)\n",
      "Step #6250\tEpoch   1 Batch 3124/3125   Loss: 0.858898 mae: 0.711433 (17.126682531723308 steps/sec)\n",
      "\n",
      "Train time for epoch #2 (6250 total steps): 191.4886429309845\n",
      "Model test set loss: 0.830293 mae: 0.721214\n",
      "best loss = 0.8302927017211914\n",
      "Step #6300\tEpoch   2 Batch   49/3125   Loss: 0.914857 mae: 0.720930 (19.375512531546445 steps/sec)\n",
      "Step #6350\tEpoch   2 Batch   99/3125   Loss: 1.007536 mae: 0.709334 (17.267351854471393 steps/sec)\n",
      "Step #6400\tEpoch   2 Batch  149/3125   Loss: 0.794577 mae: 0.720989 (14.326544760273547 steps/sec)\n",
      "Step #6450\tEpoch   2 Batch  199/3125   Loss: 0.868893 mae: 0.716851 (13.293375383923776 steps/sec)\n",
      "Step #6500\tEpoch   2 Batch  249/3125   Loss: 0.820918 mae: 0.708826 (13.21319293038935 steps/sec)\n",
      "Step #6550\tEpoch   2 Batch  299/3125   Loss: 0.786811 mae: 0.717429 (13.288884802463988 steps/sec)\n",
      "Step #6600\tEpoch   2 Batch  349/3125   Loss: 0.889751 mae: 0.718143 (14.189943219305746 steps/sec)\n",
      "Step #6650\tEpoch   2 Batch  399/3125   Loss: 0.922718 mae: 0.717242 (17.30839970971535 steps/sec)\n",
      "Step #6700\tEpoch   2 Batch  449/3125   Loss: 0.802196 mae: 0.722023 (16.945510678210866 steps/sec)\n",
      "Step #6750\tEpoch   2 Batch  499/3125   Loss: 0.805192 mae: 0.708981 (17.754577059819784 steps/sec)\n",
      "Step #6800\tEpoch   2 Batch  549/3125   Loss: 0.785933 mae: 0.710183 (16.872176659562417 steps/sec)\n",
      "Step #6850\tEpoch   2 Batch  599/3125   Loss: 0.726787 mae: 0.724399 (17.807637113962315 steps/sec)\n",
      "Step #6900\tEpoch   2 Batch  649/3125   Loss: 0.773879 mae: 0.717607 (18.262559650540727 steps/sec)\n",
      "Step #6950\tEpoch   2 Batch  699/3125   Loss: 0.781449 mae: 0.717121 (17.68648677459561 steps/sec)\n",
      "Step #7000\tEpoch   2 Batch  749/3125   Loss: 0.782143 mae: 0.704678 (17.58286277222327 steps/sec)\n",
      "Step #7050\tEpoch   2 Batch  799/3125   Loss: 0.888226 mae: 0.715262 (17.53567021081164 steps/sec)\n",
      "Step #7100\tEpoch   2 Batch  849/3125   Loss: 0.948377 mae: 0.714199 (16.353855245261197 steps/sec)\n",
      "Step #7150\tEpoch   2 Batch  899/3125   Loss: 0.876377 mae: 0.712745 (17.234318379516232 steps/sec)\n",
      "Step #7200\tEpoch   2 Batch  949/3125   Loss: 0.701794 mae: 0.713630 (17.170477630544305 steps/sec)\n",
      "Step #7250\tEpoch   2 Batch  999/3125   Loss: 0.865476 mae: 0.713157 (16.727157638963334 steps/sec)\n",
      "Step #7300\tEpoch   2 Batch 1049/3125   Loss: 0.871262 mae: 0.718574 (18.617611587713267 steps/sec)\n",
      "Step #7350\tEpoch   2 Batch 1099/3125   Loss: 0.774179 mae: 0.712240 (18.69909558040523 steps/sec)\n",
      "Step #7400\tEpoch   2 Batch 1149/3125   Loss: 0.744135 mae: 0.716779 (18.76604438666596 steps/sec)\n",
      "Step #7450\tEpoch   2 Batch 1199/3125   Loss: 0.825111 mae: 0.708995 (19.731837698815376 steps/sec)\n",
      "Step #7500\tEpoch   2 Batch 1249/3125   Loss: 0.934141 mae: 0.718765 (19.478048428002296 steps/sec)\n",
      "Step #7550\tEpoch   2 Batch 1299/3125   Loss: 0.800292 mae: 0.723021 (18.7724478750986 steps/sec)\n",
      "Step #7600\tEpoch   2 Batch 1349/3125   Loss: 0.851200 mae: 0.700169 (18.766185444795262 steps/sec)\n",
      "Step #7650\tEpoch   2 Batch 1399/3125   Loss: 0.821757 mae: 0.715110 (18.63217579965066 steps/sec)\n",
      "Step #7700\tEpoch   2 Batch 1449/3125   Loss: 0.817209 mae: 0.714590 (18.848505400285106 steps/sec)\n",
      "Step #7750\tEpoch   2 Batch 1499/3125   Loss: 0.843404 mae: 0.712007 (18.893012758570922 steps/sec)\n",
      "Step #7800\tEpoch   2 Batch 1549/3125   Loss: 0.900053 mae: 0.712483 (18.662641452480102 steps/sec)\n",
      "Step #7850\tEpoch   2 Batch 1599/3125   Loss: 0.842272 mae: 0.710441 (19.002742738818938 steps/sec)\n",
      "Step #7900\tEpoch   2 Batch 1649/3125   Loss: 0.871741 mae: 0.713220 (19.4261593135291 steps/sec)\n",
      "Step #7950\tEpoch   2 Batch 1699/3125   Loss: 0.873537 mae: 0.707806 (18.85279907815865 steps/sec)\n",
      "Step #8000\tEpoch   2 Batch 1749/3125   Loss: 0.816600 mae: 0.709471 (18.762485050147763 steps/sec)\n",
      "Step #8050\tEpoch   2 Batch 1799/3125   Loss: 0.923711 mae: 0.712930 (19.088696842583367 steps/sec)\n",
      "Step #8100\tEpoch   2 Batch 1849/3125   Loss: 0.763251 mae: 0.713551 (18.782194194170167 steps/sec)\n",
      "Step #8150\tEpoch   2 Batch 1899/3125   Loss: 0.862653 mae: 0.709563 (18.84510268623444 steps/sec)\n",
      "Step #8200\tEpoch   2 Batch 1949/3125   Loss: 0.799472 mae: 0.704607 (18.735188593035716 steps/sec)\n",
      "Step #8250\tEpoch   2 Batch 1999/3125   Loss: 0.891270 mae: 0.712690 (18.920395836154572 steps/sec)\n",
      "Step #8300\tEpoch   2 Batch 2049/3125   Loss: 0.782949 mae: 0.717282 (19.448532637131894 steps/sec)\n",
      "Step #8350\tEpoch   2 Batch 2099/3125   Loss: 0.865400 mae: 0.702722 (19.134780111052148 steps/sec)\n",
      "Step #8400\tEpoch   2 Batch 2149/3125   Loss: 0.748059 mae: 0.702021 (19.105431379758567 steps/sec)\n",
      "Step #8450\tEpoch   2 Batch 2199/3125   Loss: 0.744276 mae: 0.705446 (18.662169798308334 steps/sec)\n",
      "Step #8500\tEpoch   2 Batch 2249/3125   Loss: 0.745717 mae: 0.706977 (18.420907699319844 steps/sec)\n",
      "Step #8550\tEpoch   2 Batch 2299/3125   Loss: 0.871837 mae: 0.717483 (17.579847125932663 steps/sec)\n",
      "Step #8600\tEpoch   2 Batch 2349/3125   Loss: 0.816307 mae: 0.711365 (16.761879550686302 steps/sec)\n",
      "Step #8650\tEpoch   2 Batch 2399/3125   Loss: 0.741755 mae: 0.711121 (16.350486611972524 steps/sec)\n",
      "Step #8700\tEpoch   2 Batch 2449/3125   Loss: 0.804425 mae: 0.703449 (17.291447035032718 steps/sec)\n",
      "Step #8750\tEpoch   2 Batch 2499/3125   Loss: 0.911564 mae: 0.712165 (16.524746950156246 steps/sec)\n",
      "Step #8800\tEpoch   2 Batch 2549/3125   Loss: 0.658809 mae: 0.715587 (15.306130343309794 steps/sec)\n",
      "Step #8850\tEpoch   2 Batch 2599/3125   Loss: 0.949171 mae: 0.712459 (14.856434690016428 steps/sec)\n",
      "Step #8900\tEpoch   2 Batch 2649/3125   Loss: 0.872553 mae: 0.709989 (13.75719478001826 steps/sec)\n",
      "Step #8950\tEpoch   2 Batch 2699/3125   Loss: 0.765356 mae: 0.706220 (12.51366513126313 steps/sec)\n",
      "Step #9000\tEpoch   2 Batch 2749/3125   Loss: 0.952502 mae: 0.705897 (13.300802322099758 steps/sec)\n",
      "Step #9050\tEpoch   2 Batch 2799/3125   Loss: 0.824448 mae: 0.713157 (12.991237775756515 steps/sec)\n",
      "Step #9100\tEpoch   2 Batch 2849/3125   Loss: 0.804013 mae: 0.706563 (13.164830691957881 steps/sec)\n",
      "Step #9150\tEpoch   2 Batch 2899/3125   Loss: 0.840847 mae: 0.704934 (12.796059026254488 steps/sec)\n",
      "Step #9200\tEpoch   2 Batch 2949/3125   Loss: 0.855938 mae: 0.709051 (12.920223372437844 steps/sec)\n",
      "Step #9250\tEpoch   2 Batch 2999/3125   Loss: 0.744247 mae: 0.706944 (14.44395957031336 steps/sec)\n",
      "Step #9300\tEpoch   2 Batch 3049/3125   Loss: 0.768847 mae: 0.698169 (13.722319255899826 steps/sec)\n",
      "Step #9350\tEpoch   2 Batch 3099/3125   Loss: 0.870970 mae: 0.702747 (13.69886958876714 steps/sec)\n",
      "\n",
      "Train time for epoch #3 (9375 total steps): 188.4394450187683\n",
      "Model test set loss: 0.817053 mae: 0.713445\n",
      "best loss = 0.817052960395813\n",
      "Step #9400\tEpoch   3 Batch   24/3125   Loss: 0.710516 mae: 0.713214 (42.44953941438455 steps/sec)\n",
      "Step #9450\tEpoch   3 Batch   74/3125   Loss: 0.863188 mae: 0.702662 (19.911338775751247 steps/sec)\n",
      "Step #9500\tEpoch   3 Batch  124/3125   Loss: 0.683086 mae: 0.709883 (18.32757968860579 steps/sec)\n",
      "Step #9550\tEpoch   3 Batch  174/3125   Loss: 0.739348 mae: 0.708181 (17.3412763908151 steps/sec)\n",
      "Step #9600\tEpoch   3 Batch  224/3125   Loss: 0.614926 mae: 0.704556 (17.78618953716938 steps/sec)\n",
      "Step #9650\tEpoch   3 Batch  274/3125   Loss: 0.799047 mae: 0.705646 (17.743746248129618 steps/sec)\n",
      "Step #9700\tEpoch   3 Batch  324/3125   Loss: 0.770757 mae: 0.709096 (17.531605178412324 steps/sec)\n",
      "Step #9750\tEpoch   3 Batch  374/3125   Loss: 0.805234 mae: 0.711157 (15.161167725811104 steps/sec)\n",
      "Step #9800\tEpoch   3 Batch  424/3125   Loss: 0.836207 mae: 0.712024 (15.327454604934074 steps/sec)\n",
      "Step #9850\tEpoch   3 Batch  474/3125   Loss: 0.799533 mae: 0.706979 (14.086114529207258 steps/sec)\n",
      "Step #9900\tEpoch   3 Batch  524/3125   Loss: 0.837039 mae: 0.701581 (15.101688494117933 steps/sec)\n",
      "Step #9950\tEpoch   3 Batch  574/3125   Loss: 0.863017 mae: 0.709700 (16.564442424173013 steps/sec)\n",
      "Step #10000\tEpoch   3 Batch  624/3125   Loss: 0.635369 mae: 0.707601 (13.866644943610419 steps/sec)\n",
      "Step #10050\tEpoch   3 Batch  674/3125   Loss: 0.824676 mae: 0.709029 (12.84820901473326 steps/sec)\n",
      "Step #10100\tEpoch   3 Batch  724/3125   Loss: 0.659926 mae: 0.705799 (13.819553956636367 steps/sec)\n",
      "Step #10150\tEpoch   3 Batch  774/3125   Loss: 0.748194 mae: 0.699858 (12.487430855937944 steps/sec)\n",
      "Step #10200\tEpoch   3 Batch  824/3125   Loss: 0.821216 mae: 0.705652 (10.398752597144433 steps/sec)\n",
      "Step #10250\tEpoch   3 Batch  874/3125   Loss: 0.736213 mae: 0.703679 (12.376788469753192 steps/sec)\n",
      "Step #10300\tEpoch   3 Batch  924/3125   Loss: 0.892603 mae: 0.711245 (14.538303330354248 steps/sec)\n",
      "Step #10350\tEpoch   3 Batch  974/3125   Loss: 0.751763 mae: 0.707286 (14.335536894960464 steps/sec)\n",
      "Step #10400\tEpoch   3 Batch 1024/3125   Loss: 0.790700 mae: 0.704293 (14.745872913851038 steps/sec)\n",
      "Step #10450\tEpoch   3 Batch 1074/3125   Loss: 0.842237 mae: 0.704145 (13.914824225114257 steps/sec)\n",
      "Step #10500\tEpoch   3 Batch 1124/3125   Loss: 0.794359 mae: 0.708054 (14.793104472307828 steps/sec)\n",
      "Step #10550\tEpoch   3 Batch 1174/3125   Loss: 0.751683 mae: 0.708495 (14.568092909492991 steps/sec)\n",
      "Step #10600\tEpoch   3 Batch 1224/3125   Loss: 0.758783 mae: 0.701007 (13.681492624207142 steps/sec)\n",
      "Step #10650\tEpoch   3 Batch 1274/3125   Loss: 0.896540 mae: 0.717694 (14.083015677014236 steps/sec)\n",
      "Step #10700\tEpoch   3 Batch 1324/3125   Loss: 0.722261 mae: 0.702376 (14.755524934959377 steps/sec)\n",
      "Step #10750\tEpoch   3 Batch 1374/3125   Loss: 0.761995 mae: 0.700096 (16.257926133586434 steps/sec)\n",
      "Step #10800\tEpoch   3 Batch 1424/3125   Loss: 0.784528 mae: 0.704489 (16.98417427787869 steps/sec)\n",
      "Step #10850\tEpoch   3 Batch 1474/3125   Loss: 0.696438 mae: 0.706582 (17.45335913280486 steps/sec)\n",
      "Step #10900\tEpoch   3 Batch 1524/3125   Loss: 0.707196 mae: 0.700998 (17.239660940094343 steps/sec)\n",
      "Step #10950\tEpoch   3 Batch 1574/3125   Loss: 0.778640 mae: 0.709647 (16.740531468960178 steps/sec)\n",
      "Step #11000\tEpoch   3 Batch 1624/3125   Loss: 0.837654 mae: 0.698179 (15.712321575619601 steps/sec)\n",
      "Step #11050\tEpoch   3 Batch 1674/3125   Loss: 0.734297 mae: 0.705842 (15.733537456871888 steps/sec)\n",
      "Step #11100\tEpoch   3 Batch 1724/3125   Loss: 0.899463 mae: 0.702463 (15.608601271491532 steps/sec)\n",
      "Step #11150\tEpoch   3 Batch 1774/3125   Loss: 0.761050 mae: 0.703707 (13.482190269611404 steps/sec)\n",
      "Step #11200\tEpoch   3 Batch 1824/3125   Loss: 0.706320 mae: 0.705166 (14.612054384674689 steps/sec)\n",
      "Step #11250\tEpoch   3 Batch 1874/3125   Loss: 0.872006 mae: 0.706261 (16.393673548149152 steps/sec)\n",
      "Step #11300\tEpoch   3 Batch 1924/3125   Loss: 0.976233 mae: 0.700501 (17.397459076626063 steps/sec)\n",
      "Step #11350\tEpoch   3 Batch 1974/3125   Loss: 0.785775 mae: 0.698011 (17.886937332620636 steps/sec)\n",
      "Step #11400\tEpoch   3 Batch 2024/3125   Loss: 0.840305 mae: 0.707604 (16.039111486919015 steps/sec)\n",
      "Step #11450\tEpoch   3 Batch 2074/3125   Loss: 0.825061 mae: 0.697712 (15.909150390807984 steps/sec)\n",
      "Step #11500\tEpoch   3 Batch 2124/3125   Loss: 0.652610 mae: 0.701530 (16.377977254770453 steps/sec)\n",
      "Step #11550\tEpoch   3 Batch 2174/3125   Loss: 0.726598 mae: 0.696375 (15.886587230397376 steps/sec)\n",
      "Step #11600\tEpoch   3 Batch 2224/3125   Loss: 0.701467 mae: 0.700899 (16.50734208628708 steps/sec)\n",
      "Step #11650\tEpoch   3 Batch 2274/3125   Loss: 0.822009 mae: 0.701795 (17.295536953273437 steps/sec)\n",
      "Step #11700\tEpoch   3 Batch 2324/3125   Loss: 0.659086 mae: 0.710082 (16.545564855570134 steps/sec)\n",
      "Step #11750\tEpoch   3 Batch 2374/3125   Loss: 0.749458 mae: 0.701301 (16.638541081047546 steps/sec)\n",
      "Step #11800\tEpoch   3 Batch 2424/3125   Loss: 0.751460 mae: 0.702502 (15.935071682869316 steps/sec)\n",
      "Step #11850\tEpoch   3 Batch 2474/3125   Loss: 0.862836 mae: 0.697677 (15.605833405329278 steps/sec)\n",
      "Step #11900\tEpoch   3 Batch 2524/3125   Loss: 0.768361 mae: 0.705906 (14.444537581349673 steps/sec)\n",
      "Step #11950\tEpoch   3 Batch 2574/3125   Loss: 0.887128 mae: 0.710334 (13.960423569957456 steps/sec)\n",
      "Step #12000\tEpoch   3 Batch 2624/3125   Loss: 0.950617 mae: 0.707765 (13.881982968696775 steps/sec)\n",
      "Step #12050\tEpoch   3 Batch 2674/3125   Loss: 0.788486 mae: 0.703962 (13.251004036745524 steps/sec)\n",
      "Step #12100\tEpoch   3 Batch 2724/3125   Loss: 0.767807 mae: 0.694834 (12.501581213196182 steps/sec)\n",
      "Step #12150\tEpoch   3 Batch 2774/3125   Loss: 0.730309 mae: 0.702573 (14.261241984583062 steps/sec)\n",
      "Step #12200\tEpoch   3 Batch 2824/3125   Loss: 0.797863 mae: 0.712533 (16.117105765125082 steps/sec)\n",
      "Step #12250\tEpoch   3 Batch 2874/3125   Loss: 0.814280 mae: 0.693125 (17.09861246296588 steps/sec)\n",
      "Step #12300\tEpoch   3 Batch 2924/3125   Loss: 0.817772 mae: 0.700427 (16.821089438316594 steps/sec)\n",
      "Step #12350\tEpoch   3 Batch 2974/3125   Loss: 0.727584 mae: 0.704824 (16.988358188111086 steps/sec)\n",
      "Step #12400\tEpoch   3 Batch 3024/3125   Loss: 0.707250 mae: 0.694322 (16.927943765523725 steps/sec)\n",
      "Step #12450\tEpoch   3 Batch 3074/3125   Loss: 0.791885 mae: 0.695298 (17.109253224211894 steps/sec)\n",
      "Step #12500\tEpoch   3 Batch 3124/3125   Loss: 0.851759 mae: 0.696965 (17.426085349555066 steps/sec)\n",
      "\n",
      "Train time for epoch #4 (12500 total steps): 203.36910486221313\n",
      "Model test set loss: 0.807715 mae: 0.709160\n",
      "best loss = 0.807714581489563\n",
      "Step #12550\tEpoch   4 Batch   49/3125   Loss: 0.880607 mae: 0.708706 (19.91366244107284 steps/sec)\n",
      "Step #12600\tEpoch   4 Batch   99/3125   Loss: 0.971467 mae: 0.693708 (18.74240851181495 steps/sec)\n",
      "Step #12650\tEpoch   4 Batch  149/3125   Loss: 0.764015 mae: 0.703615 (18.643520388283402 steps/sec)\n",
      "Step #12700\tEpoch   4 Batch  199/3125   Loss: 0.809355 mae: 0.702203 (18.626178639906126 steps/sec)\n",
      "Step #12750\tEpoch   4 Batch  249/3125   Loss: 0.837630 mae: 0.697351 (18.667281209196098 steps/sec)\n",
      "Step #12800\tEpoch   4 Batch  299/3125   Loss: 0.777730 mae: 0.702415 (18.73574094127365 steps/sec)\n",
      "Step #12850\tEpoch   4 Batch  349/3125   Loss: 0.857767 mae: 0.704038 (18.576697598420573 steps/sec)\n",
      "Step #12900\tEpoch   4 Batch  399/3125   Loss: 0.896423 mae: 0.705361 (18.670420540995206 steps/sec)\n",
      "Step #12950\tEpoch   4 Batch  449/3125   Loss: 0.801214 mae: 0.707330 (19.513046601351856 steps/sec)\n",
      "Step #13000\tEpoch   4 Batch  499/3125   Loss: 0.775168 mae: 0.696092 (19.365312562763027 steps/sec)\n",
      "Step #13050\tEpoch   4 Batch  549/3125   Loss: 0.769530 mae: 0.696542 (19.277992682247707 steps/sec)\n",
      "Step #13100\tEpoch   4 Batch  599/3125   Loss: 0.695271 mae: 0.707921 (19.091270414207756 steps/sec)\n",
      "Step #13150\tEpoch   4 Batch  649/3125   Loss: 0.741783 mae: 0.704197 (18.17094019611929 steps/sec)\n",
      "Step #13200\tEpoch   4 Batch  699/3125   Loss: 0.776103 mae: 0.702454 (19.001239657216026 steps/sec)\n",
      "Step #13250\tEpoch   4 Batch  749/3125   Loss: 0.753925 mae: 0.690925 (19.53197442120812 steps/sec)\n",
      "Step #13300\tEpoch   4 Batch  799/3125   Loss: 0.857256 mae: 0.701581 (19.36205856298145 steps/sec)\n",
      "Step #13350\tEpoch   4 Batch  849/3125   Loss: 0.900082 mae: 0.699975 (19.13184222820453 steps/sec)\n",
      "Step #13400\tEpoch   4 Batch  899/3125   Loss: 0.844578 mae: 0.698758 (19.475646248344876 steps/sec)\n",
      "Step #13450\tEpoch   4 Batch  949/3125   Loss: 0.667448 mae: 0.701193 (19.341893875944347 steps/sec)\n",
      "Step #13500\tEpoch   4 Batch  999/3125   Loss: 0.861349 mae: 0.698898 (19.39660311201813 steps/sec)\n",
      "Step #13550\tEpoch   4 Batch 1049/3125   Loss: 0.839800 mae: 0.705605 (19.156070467672933 steps/sec)\n",
      "Step #13600\tEpoch   4 Batch 1099/3125   Loss: 0.752185 mae: 0.697888 (19.451907785903536 steps/sec)\n",
      "Step #13650\tEpoch   4 Batch 1149/3125   Loss: 0.730751 mae: 0.704407 (19.485825205768688 steps/sec)\n",
      "Step #13700\tEpoch   4 Batch 1199/3125   Loss: 0.816129 mae: 0.696565 (19.27400268860662 steps/sec)\n",
      "Step #13750\tEpoch   4 Batch 1249/3125   Loss: 0.904320 mae: 0.704160 (19.349687262702098 steps/sec)\n",
      "Step #13800\tEpoch   4 Batch 1299/3125   Loss: 0.770736 mae: 0.708250 (19.26791811774261 steps/sec)\n",
      "Step #13850\tEpoch   4 Batch 1349/3125   Loss: 0.827753 mae: 0.686549 (19.237577503150764 steps/sec)\n",
      "Step #13900\tEpoch   4 Batch 1399/3125   Loss: 0.782719 mae: 0.701697 (19.197837548266886 steps/sec)\n",
      "Step #13950\tEpoch   4 Batch 1449/3125   Loss: 0.781320 mae: 0.700924 (19.13272018185076 steps/sec)\n",
      "Step #14000\tEpoch   4 Batch 1499/3125   Loss: 0.825449 mae: 0.699917 (19.33967497130383 steps/sec)\n",
      "Step #14050\tEpoch   4 Batch 1549/3125   Loss: 0.881361 mae: 0.699071 (19.333721762089844 steps/sec)\n",
      "Step #14100\tEpoch   4 Batch 1599/3125   Loss: 0.808638 mae: 0.697240 (19.42643103690717 steps/sec)\n",
      "Step #14150\tEpoch   4 Batch 1649/3125   Loss: 0.843996 mae: 0.700621 (19.17174379374637 steps/sec)\n",
      "Step #14200\tEpoch   4 Batch 1699/3125   Loss: 0.830681 mae: 0.695028 (19.34626004027642 steps/sec)\n",
      "Step #14250\tEpoch   4 Batch 1749/3125   Loss: 0.784764 mae: 0.696536 (19.450780200782056 steps/sec)\n",
      "Step #14300\tEpoch   4 Batch 1799/3125   Loss: 0.891222 mae: 0.699660 (19.378185514613392 steps/sec)\n",
      "Step #14350\tEpoch   4 Batch 1849/3125   Loss: 0.754268 mae: 0.701334 (19.499973964725925 steps/sec)\n",
      "Step #14400\tEpoch   4 Batch 1899/3125   Loss: 0.872788 mae: 0.697115 (19.478529658718543 steps/sec)\n",
      "Step #14450\tEpoch   4 Batch 1949/3125   Loss: 0.766563 mae: 0.691537 (18.270666093059862 steps/sec)\n",
      "Step #14500\tEpoch   4 Batch 1999/3125   Loss: 0.872791 mae: 0.699484 (17.755850285258344 steps/sec)\n",
      "Step #14550\tEpoch   4 Batch 2049/3125   Loss: 0.744376 mae: 0.704785 (17.103682889221677 steps/sec)\n",
      "Step #14600\tEpoch   4 Batch 2099/3125   Loss: 0.843192 mae: 0.688750 (16.624093469939602 steps/sec)\n",
      "Step #14650\tEpoch   4 Batch 2149/3125   Loss: 0.747379 mae: 0.688468 (17.05099080053112 steps/sec)\n",
      "Step #14700\tEpoch   4 Batch 2199/3125   Loss: 0.705273 mae: 0.692852 (16.643953853319854 steps/sec)\n",
      "Step #14750\tEpoch   4 Batch 2249/3125   Loss: 0.727816 mae: 0.693522 (17.443525169922722 steps/sec)\n",
      "Step #14800\tEpoch   4 Batch 2299/3125   Loss: 0.849374 mae: 0.706605 (17.278975326389947 steps/sec)\n",
      "Step #14850\tEpoch   4 Batch 2349/3125   Loss: 0.785658 mae: 0.698374 (17.54777678168148 steps/sec)\n",
      "Step #14900\tEpoch   4 Batch 2399/3125   Loss: 0.727436 mae: 0.697817 (18.00556732658255 steps/sec)\n",
      "Step #14950\tEpoch   4 Batch 2449/3125   Loss: 0.764033 mae: 0.690556 (17.832254944159413 steps/sec)\n",
      "Step #15000\tEpoch   4 Batch 2499/3125   Loss: 0.906965 mae: 0.700824 (18.183995342043733 steps/sec)\n",
      "Step #15050\tEpoch   4 Batch 2549/3125   Loss: 0.628793 mae: 0.703737 (18.371368742098344 steps/sec)\n",
      "Step #15100\tEpoch   4 Batch 2599/3125   Loss: 0.920173 mae: 0.701115 (18.249405784285553 steps/sec)\n",
      "Step #15150\tEpoch   4 Batch 2649/3125   Loss: 0.846626 mae: 0.700095 (18.50300292470953 steps/sec)\n",
      "Step #15200\tEpoch   4 Batch 2699/3125   Loss: 0.762258 mae: 0.695232 (18.23610117633023 steps/sec)\n",
      "Step #15250\tEpoch   4 Batch 2749/3125   Loss: 0.893106 mae: 0.693756 (18.237373034645888 steps/sec)\n",
      "Step #15300\tEpoch   4 Batch 2799/3125   Loss: 0.804979 mae: 0.703548 (18.31796334384378 steps/sec)\n",
      "Step #15350\tEpoch   4 Batch 2849/3125   Loss: 0.773442 mae: 0.694260 (18.26099169764149 steps/sec)\n",
      "Step #15400\tEpoch   4 Batch 2899/3125   Loss: 0.820920 mae: 0.693431 (18.082737574602053 steps/sec)\n",
      "Step #15450\tEpoch   4 Batch 2949/3125   Loss: 0.841685 mae: 0.698282 (17.908751065736833 steps/sec)\n",
      "Step #15500\tEpoch   4 Batch 2999/3125   Loss: 0.731109 mae: 0.696034 (17.848023140663546 steps/sec)\n",
      "Step #15550\tEpoch   4 Batch 3049/3125   Loss: 0.749097 mae: 0.686570 (16.98562830039559 steps/sec)\n",
      "Step #15600\tEpoch   4 Batch 3099/3125   Loss: 0.839278 mae: 0.692809 (17.175471208109773 steps/sec)\n",
      "\n",
      "Train time for epoch #5 (15625 total steps): 168.37621688842773\n",
      "Model test set loss: 0.798817 mae: 0.704888\n",
      "best loss = 0.7988170385360718\n",
      "WARNING:tensorflow:From /Users/xulei/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./models/export/assets\n"
     ]
    }
   ],
   "source": [
    "mrs_net = mrs_network()\n",
    "mrs_net.training(features, targets_values, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(mrs_net.losses['train'], label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Testing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mrs_net.losses['test'], label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate Given User and Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_movie(mrs_net, user_id_val, movie_id_val):\n",
    "    categories = np.zeros([1, 18])\n",
    "    categories[0] = movies.values[movieid2idx[movie_id_val]][2]\n",
    "    \n",
    "    titles = np.zeros([1, sentences_size])\n",
    "    titles[0] = movies.values[movieid2idx[movie_id_val]][1]\n",
    "    \n",
    "    inference_val = mrs_net.model([np.reshape(users.values[user_id_val-1][0], [1, 1]),\n",
    "              np.reshape(users.values[user_id_val-1][1], [1, 1]),\n",
    "              np.reshape(users.values[user_id_val-1][2], [1, 1]),\n",
    "              np.reshape(users.values[user_id_val-1][3], [1, 1]),\n",
    "              np.reshape(movies.values[movieid2idx[movie_id_val]][0], [1, 1]),\n",
    "              categories,  \n",
    "              titles])\n",
    "\n",
    "    return (inference_val.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save User's Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_layer_model = keras.models.Model(inputs=[mrs_net.model.input[0], mrs_net.model.input[1], mrs_net.model.input[2], mrs_net.model.input[3]], \n",
    "                                 outputs=mrs_net.model.get_layer(\"user_combine_layer_flat\").output)\n",
    "users_matrics = []\n",
    "\n",
    "for item in users.values:\n",
    "    user_combine_layer_flat_val = user_layer_model([np.reshape(item.take(0), [1, 1]), \n",
    "                                                    np.reshape(item.take(1), [1, 1]), \n",
    "                                                    np.reshape(item.take(2), [1, 1]), \n",
    "                                                    np.reshape(item.take(3), [1, 1])])  \n",
    "    users_matrics.append(user_combine_layer_flat_val)\n",
    "\n",
    "pickle.dump((np.array(users_matrics).reshape(-1, 200)), open('users_matrics.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08721562 -0.00709821 -0.06595337 ... -0.06491411 -0.02668362\n",
      "  -0.03354005]\n",
      " [ 0.07009808 -0.02590186 -0.01503292 ... -0.06701663 -0.05415995\n",
      "  -0.03795098]\n",
      " [ 0.08229617 -0.02549316 -0.02290676 ... -0.08154348 -0.00164201\n",
      "  -0.04060952]\n",
      " ...\n",
      " [ 0.05604266 -0.01856662 -0.01040919 ... -0.08118518 -0.04427848\n",
      "   0.01328425]\n",
      " [ 0.04317714 -0.03529676 -0.0363038  ... -0.07984999 -0.03262015\n",
      "  -0.01353997]\n",
      " [ 0.08058929 -0.06454856  0.02958072 ... -0.04606372 -0.08905683\n",
      "   0.04742653]]\n"
     ]
    }
   ],
   "source": [
    "users_matrics = pickle.load(open('users_matrics.pkl', mode='rb'))\n",
    "print(users_matrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Movie's Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_layer_model = keras.models.Model(inputs=[mrs_net.model.input[4], mrs_net.model.input[5], mrs_net.model.input[6]], \n",
    "                                 outputs=mrs_net.model.get_layer(\"movie_combine_layer_flat\").output)\n",
    "movie_matrics = []\n",
    "\n",
    "for item in movies.values:\n",
    "    categories = np.zeros([1, 18])\n",
    "    categories[0] = item.take(2)\n",
    "\n",
    "    titles = np.zeros([1, sentences_size])\n",
    "    titles[0] = item.take(1)\n",
    "\n",
    "    movie_combine_layer_flat_val = movie_layer_model([np.reshape(item.take(0), [1, 1]), categories, titles])  \n",
    "    movie_matrics.append(movie_combine_layer_flat_val)\n",
    "\n",
    "pickle.dump((np.array(movie_matrics).reshape(-1, 200)), open('movie_matrics.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08721562 -0.00709821 -0.06595337 ... -0.06491411 -0.02668362\n",
      "  -0.03354005]\n",
      " [ 0.07009808 -0.02590186 -0.01503292 ... -0.06701663 -0.05415995\n",
      "  -0.03795098]\n",
      " [ 0.08229617 -0.02549316 -0.02290676 ... -0.08154348 -0.00164201\n",
      "  -0.04060952]\n",
      " ...\n",
      " [ 0.05604266 -0.01856662 -0.01040919 ... -0.08118518 -0.04427848\n",
      "   0.01328425]\n",
      " [ 0.04317714 -0.03529676 -0.0363038  ... -0.07984999 -0.03262015\n",
      "  -0.01353997]\n",
      " [ 0.08058929 -0.06454856  0.02958072 ... -0.04606372 -0.08905683\n",
      "   0.04742653]]\n"
     ]
    }
   ],
   "source": [
    "users_matrics = pickle.load(open('users_matrics.pkl', mode='rb'))\n",
    "print(users_matrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend Movie\n",
    "\n",
    "#### Recommend movies with same genre\n",
    "\n",
    "The ides is to \n",
    "\n",
    "1. Compute the **cosine similarity** of the given movie and the whole movies' feature matrix\n",
    "2. Return top k max similarity values\n",
    "3. Select randomly to make sure each recommendation id distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.          1.          1.0000001  ...  1.0000001   1.\n",
      "    1.        ]]\n",
      "\n",
      " [[-1.         -1.         -1.         ... -1.         -1.\n",
      "   -1.        ]]\n",
      "\n",
      " [[-1.         -1.0000001  -1.         ... -0.99999994 -1.0000001\n",
      "   -1.0000001 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.9999999  -1.         -1.0000001  ... -1.         -1.\n",
      "   -1.0000001 ]]\n",
      "\n",
      " [[-1.0000001  -1.0000001   0.9999999  ... -1.         -0.99999994\n",
      "   -1.0000001 ]]\n",
      "\n",
      " [[ 1.0000001  -0.99999994 -0.99999994 ...  1.          1.\n",
      "    1.        ]]], shape=(200, 1, 3883), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# print(movieid2idx)\n",
    "# print(tf.reshape(movie_matrics[movieid2idx[2]], [1, 200]))\n",
    "norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keepdims=True))\n",
    "normalized_movie_matrics = movie_matrics / norm_movie_matrics\n",
    "print(tf.transpose(normalized_movie_matrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_same_genre_movie(movie_id_val, top_k = 20):\n",
    "   \n",
    "    norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keepdims=True))\n",
    "    normalized_movie_matrics = movie_matrics / norm_movie_matrics\n",
    "\n",
    "    # Recommend movies with same genre\n",
    "    probs_embeddings = tf.reshape(movie_matrics[movieid2idx[movie_id_val]], [1, 200])\n",
    "    probs_similarity = tf.matmul(probs_embeddings, tf.transpose(normalized_movie_matrics))\n",
    "    sim = (probs_similarity.numpy())\n",
    "\n",
    "    print(f\"The movie you're watching is：{ movies_origin[movieid2idx[movie_id_val]] }\")\n",
    "    print(\"Here are recommendations for you：\")\n",
    "    p = np.squeeze(sim)\n",
    "    p[np.argsort(p)[:-top_k]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    results = set()\n",
    "    while len(results) != 5:\n",
    "        c = np.random.choice(3883, 1, p=p)[0]\n",
    "        results.add(c)\n",
    "    for val in (results):\n",
    "        print(val)\n",
    "        print(movies_origin[val])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "lhs mismatch rhs shape: 200 vs. 1: [1,200] [200,1,3883] 0 0 [Op:BatchMatMulV2] name: MatMul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-6a84c2a7a6d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommend_same_genre_movie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-e0fb8efac6c7>\u001b[0m in \u001b[0;36mrecommend_same_genre_movie\u001b[0;34m(movie_id_val, top_k)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Recommend movies with same genre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprobs_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_matrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovieid2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_id_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprobs_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_movie_matrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobs_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_mat_mul_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1701\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madj_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: lhs mismatch rhs shape: 200 vs. 1: [1,200] [200,1,3883] 0 0 [Op:BatchMatMulV2] name: MatMul/"
     ]
    }
   ],
   "source": [
    "recommend_same_genre_movie(1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommend movies you may like\n",
    "\n",
    "1. Compute the **cosine similarity** of the given user and the whole movies' feature matrix\n",
    "2. Return top k max similarity values\n",
    "3. Select randomly to make sure each recommendation id distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_your_favorite_movie(user_id_val, top_k = 10):\n",
    "    # Recommend your favorite movies\n",
    "    probs_embeddings = tf.reshape(users_matrics[user_id_val-1], [1, 200])\n",
    "    probs_similarity = tf.matmul(probs_embeddings, tf.transpose(movie_matrics))\n",
    "    sim = (probs_similarity.numpy())\n",
    "    \n",
    "    print(\"Here are recommendations for you：\")\n",
    "    p = np.squeeze(sim)\n",
    "    p[np.argsort(p)[:-top_k]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    results = set()\n",
    "    while len(results) != 5:\n",
    "        c = np.random.choice(3883, 1, p=p)[0]\n",
    "        results.add(c)\n",
    "    for val in (results):\n",
    "        print(val)\n",
    "        print(movies_origin[val])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "lhs mismatch rhs shape: 200 vs. 1: [1,200] [200,1,3883] 0 0 [Op:BatchMatMulV2] name: MatMul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-44262df20058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommend_your_favorite_movie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2434\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-a5f53b22c600>\u001b[0m in \u001b[0;36mrecommend_your_favorite_movie\u001b[0;34m(user_id_val, top_k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Recommend your favorite movies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprobs_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_matrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id_val\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprobs_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_matrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobs_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_mat_mul_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1701\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madj_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: lhs mismatch rhs shape: 200 vs. 1: [1,200] [200,1,3883] 0 0 [Op:BatchMatMulV2] name: MatMul/"
     ]
    }
   ],
   "source": [
    "recommend_your_favorite_movie(2434, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommend other favorite movies according to the given movie\n",
    "\n",
    "1. Select top k users who like the given movie in order to obtain their feature matrix\n",
    "2. Calculate rating of all movies given by these users\n",
    "3. Recommend movies with highest ratings\n",
    "4. Select movies with same ratings randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def recommend_other_favorite_movie(movie_id_val, top_k = 20):\n",
    "    probs_movie_embeddings = tf.reshape(movie_matrics[movieid2idx[movie_id_val]], [1, 200])\n",
    "    probs_user_favorite_similarity = tf.matmul(probs_movie_embeddings, tf.transpose(users_matrics))\n",
    "    favorite_user_id = np.argsort(probs_user_favorite_similarity.numpy())[0][-top_k:]\n",
    "    \n",
    "    print(f\"The movie you watching is：{ movies_origin[movieid2idx[movie_id_val]] }\")\n",
    "    print(f\"People who like the movie are：{ users_origin[favorite_user_id - 1] }\")\n",
    "    \n",
    "    probs_users_embeddings = tf.reshape(users_matrics[favorite_user_id-1], [-1, 200])\n",
    "    probs_similarity = tf.matmul(probs_users_embeddings, tf.transpose(movie_matrics))\n",
    "    sim = (probs_similarity.numpy())\n",
    "    p = np.argmax(sim, 1)\n",
    "    print(\"Other movies may like：\")\n",
    "\n",
    "    if len(set(p)) < 5:\n",
    "        results = set(p)\n",
    "    else:\n",
    "        results = set()\n",
    "        while len(results) != 5:\n",
    "            c = p[random.randrange(top_k)]\n",
    "            results.add(c)\n",
    "    for val in (results):\n",
    "        print(val)\n",
    "        print(movies_origin[val])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie you watching is：[1401 'Ghosts of Mississippi (1996)' 'Drama']\n",
      "People who like the movie are：[[451 'M' 56 13]\n",
      " [1745 'M' 45 0]\n",
      " [2496 'M' 50 1]\n",
      " [1701 'F' 25 4]\n",
      " [85 'M' 18 4]\n",
      " [445 'M' 45 12]\n",
      " [4085 'F' 25 6]\n",
      " [2693 'M' 56 13]\n",
      " [4200 'M' 45 7]\n",
      " [446 'F' 50 0]\n",
      " [1669 'F' 25 17]\n",
      " [1855 'M' 18 4]\n",
      " [100 'M' 35 17]\n",
      " [5861 'F' 50 1]\n",
      " [371 'M' 18 4]\n",
      " [4800 'M' 18 4]\n",
      " [2338 'M' 45 17]\n",
      " [3901 'M' 18 14]\n",
      " [282 'M' 25 17]\n",
      " [2154 'M' 25 12]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "lhs mismatch rhs shape: 200 vs. 1: [20,200] [200,1,3883] 0 0 [Op:BatchMatMulV2] name: MatMul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-020dd0a9364a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommend_other_favorite_movie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1401\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-626fb095c11d>\u001b[0m in \u001b[0;36mrecommend_other_favorite_movie\u001b[0;34m(movie_id_val, top_k)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprobs_users_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_matrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfavorite_user_id\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprobs_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_users_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_matrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobs_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_mat_mul_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1701\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madj_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: lhs mismatch rhs shape: 200 vs. 1: [20,200] [200,1,3883] 0 0 [Op:BatchMatMulV2] name: MatMul/"
     ]
    }
   ],
   "source": [
    "recommend_other_favorite_movie(1401, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
