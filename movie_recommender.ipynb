{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System based on Collaborative Filtering\n",
    "\n",
    "**Collaborative filtering** (CF) systems work by collecting user feedback in the form of ratings for items in a given domain and exploiting similarities in rating behavior among several users in determining how to recommend an item. The main advantage is that it requires no information about users or items and the more users interact with items the more new recommendations become accurate. However, as it only consider past interactions to make recommendations, collaborative filtering suffer from the **“cold start problem”**, which means that it is impossible to recommend anything to new users or to recommend a new item to any users and many users or items have too few interactions to be efficiently handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Datasets\n",
    "\n",
    "In the project, I am planning to use [MovieLens]{https://grouplens.org/datasets/movielens/} as the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import hashlib\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from os.path import isfile, isdir\n",
    "from urllib.request import urlretrieve\n",
    "from tensorflow.python.ops import math_ops\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unzip(save_path, _, database_name, data_path):\n",
    "    \"\"\"Unzip wrapper with the same interface as _ungzip\n",
    "    Args:\n",
    "        save_path: The path of the gzip files\n",
    "        database_name: Name of database\n",
    "        data_path: Path to extract to\n",
    "        _: HACK - Used to have to same interface as _ungzip\n",
    "    \"\"\"\n",
    "    print(f'Extracting { database_name }...')\n",
    "    with zipfile.ZipFile(save_path) as zf:\n",
    "        zf.extractall(data_path)\n",
    "\n",
    "def download_extract(database_name, data_path):\n",
    "    \"\"\"Download and extract database\n",
    "    Args:\n",
    "        database_name: Database name\n",
    "        data_path: Path to extract to\n",
    "    \"\"\"\n",
    "    DATASET_NAME = 'ml-1m'\n",
    "    if database_name == DATASET_NAME:\n",
    "        url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "        hash_code = 'c4d9eecfca2ab87c1945afe126590906'\n",
    "        extract_path = os.path.join(data_path, DATASET_NAME)\n",
    "        save_path = os.path.join(data_path, f'{ DATASET_NAME }.zip')\n",
    "        extract_fn = _unzip\n",
    "        \n",
    "    if os.path.exists(extract_path):\n",
    "        print(f'Found { database_name } Data')\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc=f'Downloading { database_name }') as pbar:\n",
    "            urlretrieve(url, save_path, pbar.hook)\n",
    "\n",
    "    assert hashlib.md5(open(save_path, 'rb').read()).hexdigest() == hash_code, \\\n",
    "        f'{ save_path } file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "    os.makedirs(extract_path)\n",
    "    try:\n",
    "        extract_fn(save_path, extract_path, database_name, data_path)\n",
    "    except Exception as err:\n",
    "        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\n",
    "        raise err\n",
    "\n",
    "    print('Done downloading and extracing')\n",
    "    \n",
    "class DLProgress(tqdm):\n",
    "    \"\"\"Handle Progress Bar while Downloading\"\"\"\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        \"\"\"\n",
    "        A hook function that will be called once on establishment of the network connection and\n",
    "        once after each block read thereafter.\n",
    "        Args:\n",
    "            block_num: A count of blocks transferred so far\n",
    "            block_size: Block size in bytes\n",
    "            total_size: The total size of the file. This may be -1 on older FTP servers which do not return\n",
    "                            a file size in response to a retrieval request.\n",
    "        \"\"\"\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading ml-1m: 5.92MB [00:06, 918kB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ml-1m...\n",
      "Done downloading and extracing\n"
     ]
    }
   ],
   "source": [
    "data_dir = './'\n",
    "download_extract('ml-1m', data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Dataset\n",
    "\n",
    "The movie dataset includes three parts: users'data - **users.dat**, movies'data - **movies.dat**, ratings'data - **ratings.dat**\n",
    "\n",
    "### Uses' Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>OccupationID</th>\n",
       "      <th>Zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  OccupationID Zip-code\n",
       "0       1      F    1            10    48067\n",
       "1       2      M   56            16    70072\n",
       "2       3      M   25            15    55117\n",
       "3       4      M   45             7    02460\n",
       "4       5      M   25            20    55455"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_title = ['UserID', 'Gender', 'Age', 'OccupationID', 'Zip-code']\n",
    "users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "users.head()\n",
    "# print(users.head)\n",
    "# print('-'*20)\n",
    "# age_map = {val:idx for idx, val in enumerate(set(users['Age']))}\n",
    "# print(age_map)\n",
    "# users['Age'] = users['Age'].map(age_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies' Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_title = ['MovieID', 'Title', 'Genres']\n",
    "movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings' Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  timestamps\n",
       "0       1     1193       5   978300760\n",
       "1       1      661       3   978302109\n",
       "2       1      914       3   978301968\n",
       "3       1     3408       4   978300275\n",
       "4       1     2355       5   978824291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_title = ['UserID','MovieID', 'Rating', 'timestamps']\n",
    "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. Gender: change **F** to **0** and change **M** to **1**\n",
    "2. Age: transform to continous numbers from 0 to 7\n",
    "3. Genres: transform to digits\n",
    "4. Title: same as **Genres**\n",
    "\n",
    "Notes: The length of **Genres** and **Title** should be same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load dataset from file and then preprocessing it\"\"\"\n",
    "    # Load users' data\n",
    "    users_title = ['UserID', 'Gender', 'Age', 'JobID', 'Zip-code']\n",
    "    users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "    users = users.filter(regex='UserID|Gender|Age|JobID')\n",
    "    users_origin = users.values\n",
    "    # Preprocess users' gender and age attributes\n",
    "    gender_map = {'F':0, 'M':1}\n",
    "    users['Gender'] = users['Gender'].map(gender_map)\n",
    "    age_map = {val:idx for idx, val in enumerate(set(users['Age']))}\n",
    "    users['Age'] = users['Age'].map(age_map)\n",
    "    \n",
    "    # Load movies' data\n",
    "    movies_title = ['MovieID', 'Title', 'Genres']\n",
    "    movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "    movies_origin = movies.values\n",
    "    # Remove year from title\n",
    "    pattern = re.compile(r'^(.*)\\((\\d+)\\)$')\n",
    "    title_map = {title:pattern.match(title).group(1) for title in set(movies['Title'])}\n",
    "    movies['Title'] = movies['Title'].map(title_map)\n",
    "    # Change movies' genre to dict with numbers\n",
    "    genres_set = set()\n",
    "    for val in movies['Genres'].str.split('|'):\n",
    "        genres_set.update(val)\n",
    "    genres_set.add('<PAD>')\n",
    "    genres2int = {val:idx for idx, val in enumerate(genres_set)}\n",
    "    genres_map = {val:[genres2int[row] for row in val.split('|')] for val in set(movies['Genres'])}\n",
    "    for key in genres_map:\n",
    "        for cnt in range(max(genres2int.values()) - len(genres_map[key])):\n",
    "            genres_map[key].insert(len(genres_map[key]) + cnt, genres2int['<PAD>'])\n",
    "    movies['Genres'] = movies['Genres'].map(genres_map)\n",
    "\n",
    "    # Change movies' title to dict with numbers\n",
    "    title_set = set()\n",
    "    for val in movies['Title'].str.split():\n",
    "        title_set.update(val)\n",
    "    title_set.add('<PAD>')\n",
    "    title2int = {val:idx for idx, val in enumerate(title_set)}\n",
    "    title_count = 15\n",
    "    title_map = {val:[title2int[row] for row in val.split()] for val in set(movies['Title'])}\n",
    "    for key in title_map:\n",
    "        for cnt in range(title_count - len(title_map[key])):\n",
    "            title_map[key].insert(len(title_map[key]) + cnt, title2int['<PAD>'])\n",
    "    movies['Title'] = movies['Title'].map(title_map)\n",
    "\n",
    "    # Load ratings' data\n",
    "    ratings_title = ['UserID','MovieID', 'ratings', 'timestamps']\n",
    "    ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "    ratings = ratings.filter(regex='UserID|MovieID|ratings')\n",
    "\n",
    "    # Merge\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    \n",
    "    # Split data into two parts\n",
    "    target_fields = ['ratings']\n",
    "    features_pd, targets_pd = data.drop(target_fields, axis=1), data[target_fields]\n",
    "    features = features_pd.values\n",
    "    targets_values = targets_pd.values\n",
    "    \n",
    "    return title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin = load_data()\n",
    "pickle.dump((title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin), open('preprocess_movies.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>JobID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  Gender  Age  JobID\n",
       "0       1       0    0     10\n",
       "1       2       1    5     16\n",
       "2       3       1    6     15\n",
       "3       4       1    2      7\n",
       "4       5       1    6     20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2290, 2750, 3996, 3996, 3996, 3996, 3996, 399...</td>\n",
       "      <td>[11, 9, 7, 16, 16, 16, 16, 16, 16, 16, 16, 16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[2224, 3996, 3996, 3996, 3996, 3996, 3996, 399...</td>\n",
       "      <td>[2, 9, 1, 16, 16, 16, 16, 16, 16, 16, 16, 16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1866, 1299, 2232, 3996, 3996, 3996, 3996, 399...</td>\n",
       "      <td>[7, 18, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[4659, 387, 3960, 3996, 3996, 3996, 3996, 3996...</td>\n",
       "      <td>[7, 17, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1516, 669, 4734, 187, 763, 3802, 3996, 3996, ...</td>\n",
       "      <td>[7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                                              Title  \\\n",
       "0        1  [2290, 2750, 3996, 3996, 3996, 3996, 3996, 399...   \n",
       "1        2  [2224, 3996, 3996, 3996, 3996, 3996, 3996, 399...   \n",
       "2        3  [1866, 1299, 2232, 3996, 3996, 3996, 3996, 399...   \n",
       "3        4  [4659, 387, 3960, 3996, 3996, 3996, 3996, 3996...   \n",
       "4        5  [1516, 669, 4734, 187, 763, 3802, 3996, 3996, ...   \n",
       "\n",
       "                                              Genres  \n",
       "0  [11, 9, 7, 16, 16, 16, 16, 16, 16, 16, 16, 16,...  \n",
       "1  [2, 9, 1, 16, 16, 16, 16, 16, 16, 16, 16, 16, ...  \n",
       "2  [7, 18, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...  \n",
       "3  [7, 17, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...  \n",
       "4  [7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(params):\n",
    "    \"\"\"Save parameters to file\"\"\"\n",
    "    pickle.dump(params, open('params.pkl', 'wb'))\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    \"\"\"Load parameters from file\"\"\"\n",
    "    return pickle.load(open('params.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of matrix\n",
    "embed_dim = 32\n",
    "# Number of users' ids\n",
    "uid_max = max(features.take(0,1)) + 1 # 6040\n",
    "# Number of genders\n",
    "gender_max = max(features.take(2,1)) + 1 # 1 + 1 = 2\n",
    "# Number of ages\n",
    "age_max = max(features.take(3,1)) + 1 # 6 + 1 = 7\n",
    "# Number of jobs\n",
    "job_max = max(features.take(4,1)) + 1# 20 + 1 = 21\n",
    "\n",
    "# Number of movies\n",
    "movie_id_max = max(features.take(1,1)) + 1 # 3952\n",
    "# Number of genres\n",
    "movie_categories_max = max(genres2int.values()) + 1 # 18 + 1 = 19\n",
    "# Number of words of movies' names\n",
    "movie_title_max = len(title_set) # 5216\n",
    "\n",
    "combiner = \"sum\"\n",
    "\n",
    "# Length of movies' name\n",
    "sentences_size = title_count # = 15\n",
    "\n",
    "window_sizes = {2, 3, 4, 5}\n",
    "filter_num = 8\n",
    "movieid2idx = {val[0]:idx for idx, val in enumerate(movies.values)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 5\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "\n",
    "dropout_keep = 0.5\n",
    "# Learning Rate\n",
    "learning_rate = 0.0001\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 20\n",
    "\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    uid = tf.keras.layers.Input(shape=(1,), dtype='int32', name='uid')  \n",
    "    user_gender = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_gender')  \n",
    "    user_age = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_age') \n",
    "    user_job = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_job')\n",
    "\n",
    "    movie_id = tf.keras.layers.Input(shape=(1,), dtype='int32', name='movie_id') \n",
    "    movie_categories = tf.keras.layers.Input(shape=(18,), dtype='int32', name='movie_categories') \n",
    "    movie_titles = tf.keras.layers.Input(shape=(15,), dtype='int32', name='movie_titles') \n",
    "    return uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network\n",
    "\n",
    "#### Define User's Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding(uid, user_gender, user_age, user_job):\n",
    "    uid_embed_layer = tf.keras.layers.Embedding(uid_max, embed_dim, input_length=1, name='uid_embed_layer')(uid)\n",
    "    gender_embed_layer = tf.keras.layers.Embedding(gender_max, embed_dim // 2, input_length=1, name='gender_embed_layer')(user_gender)\n",
    "    age_embed_layer = tf.keras.layers.Embedding(age_max, embed_dim // 2, input_length=1, name='age_embed_layer')(user_age)\n",
    "    job_embed_layer = tf.keras.layers.Embedding(job_max, embed_dim // 2, input_length=1, name='job_embed_layer')(user_job)\n",
    "    return uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define User's Feature\n",
    "\n",
    "It is based on two fully connected layers, **1x128** and **1x200**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feature_layer(uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer):\n",
    "    # First FCL\n",
    "    uid_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"uid_fc_layer\", activation='relu')(uid_embed_layer)\n",
    "    gender_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"gender_fc_layer\", activation='relu')(gender_embed_layer)\n",
    "    age_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"age_fc_layer\", activation='relu')(age_embed_layer)\n",
    "    job_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"job_fc_layer\", activation='relu')(job_embed_layer)\n",
    "\n",
    "    # Second FCL\n",
    "    user_combine_layer = tf.keras.layers.concatenate([uid_fc_layer, gender_fc_layer, age_fc_layer, job_fc_layer], 2)  #(?, 1, 128)\n",
    "    user_combine_layer = tf.keras.layers.Dense(200, activation='tanh')(user_combine_layer)  #(?, 1, 200)\n",
    "\n",
    "    user_combine_layer_flat = tf.keras.layers.Reshape([200], name=\"user_combine_layer_flat\")(user_combine_layer)\n",
    "    return user_combine_layer, user_combine_layer_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Movie's ID Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_id_embed_layer(movie_id):\n",
    "    movie_id_embed_layer = tf.keras.layers.Embedding(movie_id_max, embed_dim, input_length=1, name='movie_id_embed_layer')(movie_id)\n",
    "    return movie_id_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Movie's Genre Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_categories_layers(movie_categories):\n",
    "    movie_categories_embed_layer = tf.keras.layers.Embedding(movie_categories_max, embed_dim, input_length=18, name='movie_categories_embed_layer')(movie_categories)\n",
    "    movie_categories_embed_layer = tf.keras.layers.Lambda(lambda layer: tf.reduce_sum(layer, axis=1, keepdims=True))(movie_categories_embed_layer)\n",
    "    return movie_categories_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define CNN of Movie's Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_cnn_layer(movie_titles):\n",
    "    movie_title_embed_layer = tf.keras.layers.Embedding(movie_title_max, embed_dim, input_length=15, name='movie_title_embed_layer')(movie_titles)\n",
    "    sp = movie_title_embed_layer.shape\n",
    "    movie_title_embed_layer_expand = tf.keras.layers.Reshape([sp[1], sp[2], 1])(movie_title_embed_layer)\n",
    "    pool_layer_lst = []\n",
    "    for window_size in window_sizes:\n",
    "        conv_layer = tf.keras.layers.Conv2D(filter_num, (window_size, embed_dim), 1, activation='relu')(movie_title_embed_layer_expand)\n",
    "        maxpool_layer = tf.keras.layers.MaxPooling2D(pool_size=(sentences_size - window_size + 1 ,1), strides=1)(conv_layer)\n",
    "        pool_layer_lst.append(maxpool_layer)\n",
    "    pool_layer = tf.keras.layers.concatenate(pool_layer_lst, 3, name =\"pool_layer\")  \n",
    "    max_num = len(window_sizes) * filter_num\n",
    "    pool_layer_flat = tf.keras.layers.Reshape([1, max_num], name = \"pool_layer_flat\")(pool_layer)\n",
    "\n",
    "    dropout_layer = tf.keras.layers.Dropout(dropout_keep, name = \"dropout_layer\")(pool_layer_flat)\n",
    "    return pool_layer_flat, dropout_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Movie's Feature\n",
    "\n",
    "It is based on two fully connected layers, **1x64** and **1x200**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_feature_layer(movie_id_embed_layer, movie_categories_embed_layer, dropout_layer):\n",
    "    # First FCL 64\n",
    "    movie_id_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"movie_id_fc_layer\", activation='relu')(movie_id_embed_layer)\n",
    "    movie_categories_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"movie_categories_fc_layer\", activation='relu')(movie_categories_embed_layer)\n",
    "\n",
    "    # Second FCL 200\n",
    "    movie_combine_layer = tf.keras.layers.concatenate([movie_id_fc_layer, movie_categories_fc_layer, dropout_layer], 2)  \n",
    "    movie_combine_layer = tf.keras.layers.Dense(200, activation='tanh')(movie_combine_layer)\n",
    "\n",
    "    movie_combine_layer_flat = tf.keras.layers.Reshape([200], name=\"movie_combine_layer_flat\")(movie_combine_layer)\n",
    "    return movie_combine_layer, movie_combine_layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_core.keras.layers' from '/Users/xulei/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/keras/api/_v2/keras/layers/__init__.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Computing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.ops import summary_ops_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mrs_network():\n",
    "    def __init__(self, batch_size=256):\n",
    "        self.batch_size = batch_size\n",
    "        self.best_loss = 9999\n",
    "        self.losses = {'train': [], 'test': []}\n",
    "        \n",
    "        # User's input\n",
    "        uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles = get_inputs()\n",
    "        \n",
    "        # User's embedding layers\n",
    "        uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer = get_user_embedding(uid, \n",
    "                                                                                                   user_gender,\n",
    "                                                                                                   user_age,\n",
    "                                                                                                   user_job)\n",
    "        # User's feature\n",
    "        user_combine_layer, user_combine_layer_flat = get_user_feature_layer(uid_embed_layer, \n",
    "                                                                             gender_embed_layer, \n",
    "                                                                             age_embed_layer, \n",
    "                                                                             job_embed_layer)\n",
    "        \n",
    "        # Movie's id embedding layer\n",
    "        movie_id_embed_layer = get_movie_id_embed_layer(movie_id)\n",
    "        # Movie's genre embedding layer\n",
    "        movie_categories_embed_layer = get_movie_categories_layers(movie_categories)\n",
    "        # Movie's name layer\n",
    "        pool_layer_flat, dropout_layer = get_movie_cnn_layer(movie_titles)\n",
    "        # Movie's feature\n",
    "        movie_combine_layer, movie_combine_layer_flat = get_movie_feature_layer(movie_id_embed_layer,\n",
    "                                                                                movie_categories_embed_layer,\n",
    "                                                                                dropout_layer)\n",
    "        # Combine user's feature and movie's feature to get rating prediction\n",
    "        inference = tf.keras.layers.Lambda(lambda layer: \n",
    "            tf.reduce_sum(layer[0] * layer[1], axis=1), name=\"inference\")((user_combine_layer_flat, movie_combine_layer_flat))\n",
    "        inference = tf.keras.layers.Lambda(lambda layer: tf.expand_dims(layer, axis=1))(inference)\n",
    "        \n",
    "        self.model = tf.keras.Model(\n",
    "            inputs=[uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles],\n",
    "            outputs=[inference])\n",
    "\n",
    "        self.model.summary()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        # MSE Loss\n",
    "        self.ComputeLoss = tf.keras.losses.MeanSquaredError()\n",
    "        self.ComputeMetrics = tf.keras.metrics.MeanAbsoluteError()\n",
    "        \n",
    "        if tf.io.gfile.exists(MODEL_DIR):\n",
    "            pass\n",
    "        else:\n",
    "            tf.io.gfile.makedirs(MODEL_DIR)\n",
    "\n",
    "        train_dir = os.path.join(MODEL_DIR, 'summaries', 'train')\n",
    "        test_dir = os.path.join(MODEL_DIR, 'summaries', 'eval')\n",
    "\n",
    "        checkpoint_dir = os.path.join(MODEL_DIR, 'checkpoints')\n",
    "        self.checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "        self.checkpoint = tf.train.Checkpoint(model=self.model, optimizer=self.optimizer)\n",
    "\n",
    "        # Restore variables on creation if a checkpoint exists.\n",
    "        self.checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    def compute_loss(self, labels, logits):\n",
    "        return tf.reduce_mean(tf.keras.losses.mse(labels, logits))\n",
    "\n",
    "    def compute_metrics(self, labels, logits):\n",
    "        return tf.keras.metrics.mae(labels, logits)\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model([x[0],\n",
    "                                 x[1],\n",
    "                                 x[2],\n",
    "                                 x[3],\n",
    "                                 x[4],\n",
    "                                 x[5],\n",
    "                                 x[6]], training=True)\n",
    "            loss = self.ComputeLoss(y, logits)\n",
    "            self.ComputeMetrics(y, logits)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        return loss, logits\n",
    "    \n",
    "    def training(self, features, targets_values, epochs=5, log_freq=50):\n",
    "        for epoch_i in range(epochs):\n",
    "            # separate the dataset into training and testing\n",
    "            train_X, test_X, train_y, test_y = train_test_split(features,\n",
    "                                                                targets_values,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "            train_batches = get_batches(train_X, train_y, self.batch_size)\n",
    "            batch_num = (len(train_X) // self.batch_size)\n",
    "            train_start = time.time()\n",
    "            \n",
    "            if True:\n",
    "                start = time.time()\n",
    "                avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "                for batch_i in range(batch_num):\n",
    "                    x, y = next(train_batches)\n",
    "                    categories = np.zeros([self.batch_size, 18])\n",
    "                    for i in range(self.batch_size):\n",
    "                        categories[i] = x.take(6, 1)[i]\n",
    "\n",
    "                    titles = np.zeros([self.batch_size, sentences_size])\n",
    "                    for i in range(self.batch_size):\n",
    "                        titles[i] = x.take(5, 1)[i]\n",
    "\n",
    "                    loss, logits = self.train_step([np.reshape(x.take(0, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    np.reshape(x.take(2, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    np.reshape(x.take(3, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    np.reshape(x.take(4, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    np.reshape(x.take(1, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                                    categories.astype(np.float32),\n",
    "                                                    titles.astype(np.float32)],\n",
    "                                                   np.reshape(y, [self.batch_size, 1]).astype(np.float32))\n",
    "                    avg_loss(loss)\n",
    "                    self.losses['train'].append(loss)\n",
    "\n",
    "                    if tf.equal(self.optimizer.iterations % log_freq, 0):\n",
    "                        rate = log_freq / (time.time() - start)\n",
    "                        print('Step #{}\\tEpoch {:>3} Batch {:>4}/{}   Loss: {:0.6f} mae: {:0.6f} ({} steps/sec)'.format(\n",
    "                            self.optimizer.iterations.numpy(),\n",
    "                            epoch_i,\n",
    "                            batch_i,\n",
    "                            batch_num,\n",
    "                            loss, (self.ComputeMetrics.result()), rate))\n",
    "                        avg_loss.reset_states()\n",
    "                        self.ComputeMetrics.reset_states()\n",
    "                        start = time.time()\n",
    "\n",
    "            train_end = time.time()\n",
    "            print('\\nTrain time for epoch #{} ({} total steps): {}'.format(epoch_i + 1, \n",
    "                                                                           self.optimizer.iterations.numpy(),\n",
    "                                                                           train_end - train_start))\n",
    "            self.testing((test_X, test_y), self.optimizer.iterations)\n",
    "        self.export_path = os.path.join(MODEL_DIR, 'export')\n",
    "        tf.saved_model.save(self.model, self.export_path)\n",
    "    \n",
    "    def testing(self, test_dataset, step_num):\n",
    "        test_X, test_y = test_dataset\n",
    "        test_batches = get_batches(test_X, test_y, self.batch_size)\n",
    "\n",
    "        avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "        batch_num = (len(test_X) // self.batch_size)\n",
    "        for batch_i in range(batch_num):\n",
    "            x, y = next(test_batches)\n",
    "            categories = np.zeros([self.batch_size, 18])\n",
    "            for i in range(self.batch_size):\n",
    "                categories[i] = x.take(6, 1)[i]\n",
    "\n",
    "            titles = np.zeros([self.batch_size, sentences_size])\n",
    "            for i in range(self.batch_size):\n",
    "                titles[i] = x.take(5, 1)[i]\n",
    "\n",
    "            logits = self.model([np.reshape(x.take(0, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 np.reshape(x.take(2, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 np.reshape(x.take(3, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 np.reshape(x.take(4, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 np.reshape(x.take(1, 1), [self.batch_size, 1]).astype(np.float32),\n",
    "                                 categories.astype(np.float32),\n",
    "                                 titles.astype(np.float32)], training=False)\n",
    "            test_loss = self.ComputeLoss(np.reshape(y, [self.batch_size, 1]).astype(np.float32), logits)\n",
    "            avg_loss(test_loss)\n",
    "            # Save testing loss\n",
    "            self.losses['test'].append(test_loss)\n",
    "            self.ComputeMetrics(np.reshape(y, [self.batch_size, 1]).astype(np.float32), logits)\n",
    "\n",
    "        print('Model test set loss: {:0.6f} mae: {:0.6f}'.format(avg_loss.result(), \n",
    "                                                                 self.ComputeMetrics.result()))\n",
    "\n",
    "        if avg_loss.result() < self.best_loss:\n",
    "            self.best_loss = avg_loss.result()\n",
    "            print(f'best loss = { self.best_loss }')\n",
    "            self.checkpoint.save(self.checkpoint_prefix)\n",
    "\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        predictions = self.model(xs)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(Xs, ys, batch_size):\n",
    "    for start in range(0, len(Xs), batch_size):\n",
    "        end = min(start + batch_size, len(Xs))\n",
    "        yield Xs[start:end], ys[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network\n",
    "\n",
    "Input the user's feature and movie's feature, output the training result through the fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "movie_titles (InputLayer)       [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_title_embed_layer (Embedd (None, 15, 32)       166880      movie_titles[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 15, 32, 1)    0           movie_title_embed_layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 1, 8)     520         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 13, 1, 8)     776         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 12, 1, 8)     1032        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 11, 1, 8)     1288        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "movie_categories (InputLayer)   [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 1, 1, 8)      0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 8)      0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 8)      0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 8)      0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "uid (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_gender (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_age (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_job (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_categories_embed_layer (E (None, 18, 32)       608         movie_categories[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool_layer (Concatenate)        (None, 1, 1, 32)     0           max_pooling2d[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "uid_embed_layer (Embedding)     (None, 1, 32)        193312      uid[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gender_embed_layer (Embedding)  (None, 1, 16)        32          user_gender[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "age_embed_layer (Embedding)     (None, 1, 16)        112         user_age[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "job_embed_layer (Embedding)     (None, 1, 16)        336         user_job[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "movie_id_embed_layer (Embedding (None, 1, 32)        126496      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1, 32)        0           movie_categories_embed_layer[0][0\n",
      "__________________________________________________________________________________________________\n",
      "pool_layer_flat (Reshape)       (None, 1, 32)        0           pool_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "uid_fc_layer (Dense)            (None, 1, 32)        1056        uid_embed_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gender_fc_layer (Dense)         (None, 1, 32)        544         gender_embed_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "age_fc_layer (Dense)            (None, 1, 32)        544         age_embed_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "job_fc_layer (Dense)            (None, 1, 32)        544         job_embed_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id_fc_layer (Dense)       (None, 1, 32)        1056        movie_id_embed_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "movie_categories_fc_layer (Dens (None, 1, 32)        1056        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_layer (Dropout)         (None, 1, 32)        0           pool_layer_flat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 128)       0           uid_fc_layer[0][0]               \n",
      "                                                                 gender_fc_layer[0][0]            \n",
      "                                                                 age_fc_layer[0][0]               \n",
      "                                                                 job_fc_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 96)        0           movie_id_fc_layer[0][0]          \n",
      "                                                                 movie_categories_fc_layer[0][0]  \n",
      "                                                                 dropout_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 200)       25800       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 200)       19400       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "user_combine_layer_flat (Reshap (None, 200)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "movie_combine_layer_flat (Resha (None, 200)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inference (Lambda)              (None,)              0           user_combine_layer_flat[0][0]    \n",
      "                                                                 movie_combine_layer_flat[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           inference[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 541,392\n",
      "Trainable params: 541,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Step #15650\tEpoch   0 Batch   24/3125   Loss: 0.734802 mae: 0.736746 (11.15424031459805 steps/sec)\n",
      "Step #15700\tEpoch   0 Batch   74/3125   Loss: 0.900843 mae: 0.710866 (27.56892685246277 steps/sec)\n",
      "Step #15750\tEpoch   0 Batch  124/3125   Loss: 0.667838 mae: 0.710672 (27.362042738317925 steps/sec)\n",
      "Step #15800\tEpoch   0 Batch  174/3125   Loss: 0.759331 mae: 0.708300 (27.498847085890755 steps/sec)\n",
      "Step #15850\tEpoch   0 Batch  224/3125   Loss: 0.618940 mae: 0.703708 (27.12944217268184 steps/sec)\n",
      "Step #15900\tEpoch   0 Batch  274/3125   Loss: 0.788842 mae: 0.701653 (24.040636621449778 steps/sec)\n",
      "Step #15950\tEpoch   0 Batch  324/3125   Loss: 0.777157 mae: 0.704003 (25.335006103759685 steps/sec)\n",
      "Step #16000\tEpoch   0 Batch  374/3125   Loss: 0.826017 mae: 0.705219 (24.817479895984782 steps/sec)\n",
      "Step #16050\tEpoch   0 Batch  424/3125   Loss: 0.847684 mae: 0.707202 (24.671279324284168 steps/sec)\n",
      "Step #16100\tEpoch   0 Batch  474/3125   Loss: 0.812713 mae: 0.702810 (24.803666655312448 steps/sec)\n",
      "Step #16150\tEpoch   0 Batch  524/3125   Loss: 0.812563 mae: 0.696930 (24.77498279049102 steps/sec)\n",
      "Step #16200\tEpoch   0 Batch  574/3125   Loss: 0.842472 mae: 0.704753 (24.25867754561157 steps/sec)\n",
      "Step #16250\tEpoch   0 Batch  624/3125   Loss: 0.609324 mae: 0.701256 (24.491073376337336 steps/sec)\n",
      "Step #16300\tEpoch   0 Batch  674/3125   Loss: 0.794697 mae: 0.703523 (24.15720280558029 steps/sec)\n",
      "Step #16350\tEpoch   0 Batch  724/3125   Loss: 0.657354 mae: 0.700350 (24.129563487908595 steps/sec)\n",
      "Step #16400\tEpoch   0 Batch  774/3125   Loss: 0.736186 mae: 0.694470 (23.685649050429046 steps/sec)\n",
      "Step #16450\tEpoch   0 Batch  824/3125   Loss: 0.819327 mae: 0.701006 (23.49588762138802 steps/sec)\n",
      "Step #16500\tEpoch   0 Batch  874/3125   Loss: 0.726439 mae: 0.697384 (23.443710889457222 steps/sec)\n",
      "Step #16550\tEpoch   0 Batch  924/3125   Loss: 0.876938 mae: 0.704421 (23.240020204164903 steps/sec)\n",
      "Step #16600\tEpoch   0 Batch  974/3125   Loss: 0.756350 mae: 0.700983 (22.926912834521996 steps/sec)\n",
      "Step #16650\tEpoch   0 Batch 1024/3125   Loss: 0.765276 mae: 0.696591 (23.11908918493093 steps/sec)\n",
      "Step #16700\tEpoch   0 Batch 1074/3125   Loss: 0.827900 mae: 0.698957 (23.127321731545113 steps/sec)\n",
      "Step #16750\tEpoch   0 Batch 1124/3125   Loss: 0.781298 mae: 0.702983 (23.020109467670288 steps/sec)\n",
      "Step #16800\tEpoch   0 Batch 1174/3125   Loss: 0.744629 mae: 0.702118 (22.89839722837012 steps/sec)\n",
      "Step #16850\tEpoch   0 Batch 1224/3125   Loss: 0.746374 mae: 0.694184 (22.88364037599341 steps/sec)\n",
      "Step #16900\tEpoch   0 Batch 1274/3125   Loss: 0.879436 mae: 0.711179 (23.16654555834398 steps/sec)\n",
      "Step #16950\tEpoch   0 Batch 1324/3125   Loss: 0.706683 mae: 0.695140 (23.022684647869575 steps/sec)\n",
      "Step #17000\tEpoch   0 Batch 1374/3125   Loss: 0.735550 mae: 0.693847 (22.282921161046243 steps/sec)\n",
      "Step #17050\tEpoch   0 Batch 1424/3125   Loss: 0.783719 mae: 0.698049 (22.38171103836782 steps/sec)\n",
      "Step #17100\tEpoch   0 Batch 1474/3125   Loss: 0.707327 mae: 0.700482 (22.786441865427836 steps/sec)\n",
      "Step #17150\tEpoch   0 Batch 1524/3125   Loss: 0.699388 mae: 0.694002 (22.47477691890891 steps/sec)\n",
      "Step #17200\tEpoch   0 Batch 1574/3125   Loss: 0.769059 mae: 0.702318 (19.19849484456617 steps/sec)\n",
      "Step #17250\tEpoch   0 Batch 1624/3125   Loss: 0.810261 mae: 0.691987 (20.50641803385768 steps/sec)\n",
      "Step #17300\tEpoch   0 Batch 1674/3125   Loss: 0.711050 mae: 0.700097 (19.36082340220622 steps/sec)\n",
      "Step #17350\tEpoch   0 Batch 1724/3125   Loss: 0.875329 mae: 0.695706 (18.480462667192224 steps/sec)\n",
      "Step #17400\tEpoch   0 Batch 1774/3125   Loss: 0.763017 mae: 0.698105 (15.795796619116002 steps/sec)\n",
      "Step #17450\tEpoch   0 Batch 1824/3125   Loss: 0.705050 mae: 0.697844 (13.307948743299074 steps/sec)\n",
      "Step #17500\tEpoch   0 Batch 1874/3125   Loss: 0.849646 mae: 0.699676 (14.881807134972252 steps/sec)\n",
      "Step #17550\tEpoch   0 Batch 1924/3125   Loss: 0.962175 mae: 0.693377 (16.575566934986437 steps/sec)\n",
      "Step #17600\tEpoch   0 Batch 1974/3125   Loss: 0.772495 mae: 0.691902 (17.043359650425963 steps/sec)\n",
      "Step #17650\tEpoch   0 Batch 2024/3125   Loss: 0.846181 mae: 0.701157 (19.617144497064846 steps/sec)\n",
      "Step #17700\tEpoch   0 Batch 2074/3125   Loss: 0.815310 mae: 0.690981 (20.409287002581582 steps/sec)\n",
      "Step #17750\tEpoch   0 Batch 2124/3125   Loss: 0.639199 mae: 0.694110 (20.287316064600116 steps/sec)\n",
      "Step #17800\tEpoch   0 Batch 2174/3125   Loss: 0.727806 mae: 0.690490 (20.760230676269202 steps/sec)\n",
      "Step #17850\tEpoch   0 Batch 2224/3125   Loss: 0.690799 mae: 0.694409 (19.30671721953341 steps/sec)\n",
      "Step #17900\tEpoch   0 Batch 2274/3125   Loss: 0.801511 mae: 0.695032 (19.13813280846755 steps/sec)\n",
      "Step #17950\tEpoch   0 Batch 2324/3125   Loss: 0.646507 mae: 0.704049 (19.63888607171991 steps/sec)\n",
      "Step #18000\tEpoch   0 Batch 2374/3125   Loss: 0.739624 mae: 0.693934 (19.33074029525681 steps/sec)\n",
      "Step #18050\tEpoch   0 Batch 2424/3125   Loss: 0.738662 mae: 0.695172 (19.55999268768584 steps/sec)\n",
      "Step #18100\tEpoch   0 Batch 2474/3125   Loss: 0.844751 mae: 0.690791 (20.175152267106196 steps/sec)\n",
      "Step #18150\tEpoch   0 Batch 2524/3125   Loss: 0.762681 mae: 0.700348 (20.05763785781208 steps/sec)\n",
      "Step #18200\tEpoch   0 Batch 2574/3125   Loss: 0.867405 mae: 0.704618 (20.684824199628313 steps/sec)\n",
      "Step #18250\tEpoch   0 Batch 2624/3125   Loss: 0.943483 mae: 0.701101 (19.77540464975931 steps/sec)\n",
      "Step #18300\tEpoch   0 Batch 2674/3125   Loss: 0.771820 mae: 0.697344 (18.303755026403675 steps/sec)\n",
      "Step #18350\tEpoch   0 Batch 2724/3125   Loss: 0.746369 mae: 0.689061 (18.004120472746898 steps/sec)\n",
      "Step #18400\tEpoch   0 Batch 2774/3125   Loss: 0.709702 mae: 0.696525 (17.655829394244364 steps/sec)\n",
      "Step #18450\tEpoch   0 Batch 2824/3125   Loss: 0.784749 mae: 0.706527 (17.84997675500559 steps/sec)\n",
      "Step #18500\tEpoch   0 Batch 2874/3125   Loss: 0.800431 mae: 0.686313 (16.175005034558552 steps/sec)\n",
      "Step #18550\tEpoch   0 Batch 2924/3125   Loss: 0.798830 mae: 0.694721 (12.839336926005537 steps/sec)\n",
      "Step #18600\tEpoch   0 Batch 2974/3125   Loss: 0.717084 mae: 0.698075 (13.490274037273043 steps/sec)\n",
      "Step #18650\tEpoch   0 Batch 3024/3125   Loss: 0.712684 mae: 0.688062 (18.507709000828243 steps/sec)\n",
      "Step #18700\tEpoch   0 Batch 3074/3125   Loss: 0.771031 mae: 0.689861 (19.011557681617475 steps/sec)\n",
      "Step #18750\tEpoch   0 Batch 3124/3125   Loss: 0.831301 mae: 0.690904 (20.31609435362012 steps/sec)\n",
      "\n",
      "Train time for epoch #1 (18750 total steps): 156.05099511146545\n",
      "Model test set loss: 0.797975 mae: 0.705099\n",
      "best loss = 0.7979745864868164\n",
      "Step #18800\tEpoch   1 Batch   49/3125   Loss: 0.841609 mae: 0.704478 (24.42602421134236 steps/sec)\n",
      "Step #18850\tEpoch   1 Batch   99/3125   Loss: 0.951747 mae: 0.687450 (22.67858714748275 steps/sec)\n",
      "Step #18900\tEpoch   1 Batch  149/3125   Loss: 0.741353 mae: 0.696285 (21.87144464865815 steps/sec)\n",
      "Step #18950\tEpoch   1 Batch  199/3125   Loss: 0.788447 mae: 0.696196 (21.8146088202231 steps/sec)\n",
      "Step #19000\tEpoch   1 Batch  249/3125   Loss: 0.835684 mae: 0.693171 (22.107158078336735 steps/sec)\n",
      "Step #19050\tEpoch   1 Batch  299/3125   Loss: 0.773991 mae: 0.695553 (22.048732894283095 steps/sec)\n",
      "Step #19100\tEpoch   1 Batch  349/3125   Loss: 0.836924 mae: 0.697629 (21.564986265528724 steps/sec)\n",
      "Step #19150\tEpoch   1 Batch  399/3125   Loss: 0.903658 mae: 0.699189 (22.074761387230303 steps/sec)\n",
      "Step #19200\tEpoch   1 Batch  449/3125   Loss: 0.796519 mae: 0.700366 (22.207425404554595 steps/sec)\n",
      "Step #19250\tEpoch   1 Batch  499/3125   Loss: 0.767793 mae: 0.690093 (21.415630929527257 steps/sec)\n",
      "Step #19300\tEpoch   1 Batch  549/3125   Loss: 0.756315 mae: 0.689531 (21.939880505888397 steps/sec)\n",
      "Step #19350\tEpoch   1 Batch  599/3125   Loss: 0.689926 mae: 0.700903 (22.32016223463868 steps/sec)\n",
      "Step #19400\tEpoch   1 Batch  649/3125   Loss: 0.730775 mae: 0.697289 (22.300602455440576 steps/sec)\n",
      "Step #19450\tEpoch   1 Batch  699/3125   Loss: 0.768522 mae: 0.696368 (21.27332681485503 steps/sec)\n",
      "Step #19500\tEpoch   1 Batch  749/3125   Loss: 0.749019 mae: 0.685074 (22.31596779582742 steps/sec)\n",
      "Step #19550\tEpoch   1 Batch  799/3125   Loss: 0.834012 mae: 0.695138 (22.538725483926818 steps/sec)\n",
      "Step #19600\tEpoch   1 Batch  849/3125   Loss: 0.869059 mae: 0.695018 (22.333361483185538 steps/sec)\n",
      "Step #19650\tEpoch   1 Batch  899/3125   Loss: 0.827609 mae: 0.691993 (22.277143268084554 steps/sec)\n",
      "Step #19700\tEpoch   1 Batch  949/3125   Loss: 0.660510 mae: 0.695353 (22.557965304986432 steps/sec)\n",
      "Step #19750\tEpoch   1 Batch  999/3125   Loss: 0.839161 mae: 0.690999 (22.398594961183388 steps/sec)\n",
      "Step #19800\tEpoch   1 Batch 1049/3125   Loss: 0.835122 mae: 0.699998 (22.397508919639353 steps/sec)\n",
      "Step #19850\tEpoch   1 Batch 1099/3125   Loss: 0.741078 mae: 0.692430 (22.301098087306354 steps/sec)\n",
      "Step #19900\tEpoch   1 Batch 1149/3125   Loss: 0.713959 mae: 0.700898 (21.837169416558748 steps/sec)\n",
      "Step #19950\tEpoch   1 Batch 1199/3125   Loss: 0.815515 mae: 0.689765 (21.65235223314868 steps/sec)\n",
      "Step #20000\tEpoch   1 Batch 1249/3125   Loss: 0.877457 mae: 0.697520 (22.372675949356285 steps/sec)\n",
      "Step #20050\tEpoch   1 Batch 1299/3125   Loss: 0.754385 mae: 0.702264 (22.388525607328813 steps/sec)\n",
      "Step #20100\tEpoch   1 Batch 1349/3125   Loss: 0.805303 mae: 0.680673 (22.577993940449662 steps/sec)\n",
      "Step #20150\tEpoch   1 Batch 1399/3125   Loss: 0.778678 mae: 0.695922 (22.5732209511668 steps/sec)\n",
      "Step #20200\tEpoch   1 Batch 1449/3125   Loss: 0.765973 mae: 0.695219 (22.32722936717486 steps/sec)\n",
      "Step #20250\tEpoch   1 Batch 1499/3125   Loss: 0.802552 mae: 0.694178 (21.992040863430727 steps/sec)\n",
      "Step #20300\tEpoch   1 Batch 1549/3125   Loss: 0.858103 mae: 0.692656 (22.201578473927317 steps/sec)\n",
      "Step #20350\tEpoch   1 Batch 1599/3125   Loss: 0.774565 mae: 0.690411 (22.27952412600904 steps/sec)\n",
      "Step #20400\tEpoch   1 Batch 1649/3125   Loss: 0.833182 mae: 0.695749 (22.611051895125964 steps/sec)\n",
      "Step #20450\tEpoch   1 Batch 1699/3125   Loss: 0.815976 mae: 0.689635 (22.46111894747778 steps/sec)\n",
      "Step #20500\tEpoch   1 Batch 1749/3125   Loss: 0.768308 mae: 0.690344 (22.44183256759831 steps/sec)\n",
      "Step #20550\tEpoch   1 Batch 1799/3125   Loss: 0.857947 mae: 0.693654 (22.695909837644557 steps/sec)\n",
      "Step #20600\tEpoch   1 Batch 1849/3125   Loss: 0.761956 mae: 0.695056 (22.25994569051832 steps/sec)\n",
      "Step #20650\tEpoch   1 Batch 1899/3125   Loss: 0.866287 mae: 0.692442 (22.06973425314413 steps/sec)\n",
      "Step #20700\tEpoch   1 Batch 1949/3125   Loss: 0.748562 mae: 0.684527 (22.454534202297584 steps/sec)\n",
      "Step #20750\tEpoch   1 Batch 1999/3125   Loss: 0.869664 mae: 0.693507 (22.983371743943245 steps/sec)\n",
      "Step #20800\tEpoch   1 Batch 2049/3125   Loss: 0.719659 mae: 0.700009 (22.550280954845395 steps/sec)\n",
      "Step #20850\tEpoch   1 Batch 2099/3125   Loss: 0.837718 mae: 0.682548 (22.384823911877003 steps/sec)\n",
      "Step #20900\tEpoch   1 Batch 2149/3125   Loss: 0.758759 mae: 0.683320 (22.202704362298157 steps/sec)\n",
      "Step #20950\tEpoch   1 Batch 2199/3125   Loss: 0.693828 mae: 0.687330 (22.974141448887337 steps/sec)\n",
      "Step #21000\tEpoch   1 Batch 2249/3125   Loss: 0.722274 mae: 0.686817 (22.678327189613842 steps/sec)\n",
      "Step #21050\tEpoch   1 Batch 2299/3125   Loss: 0.815394 mae: 0.700671 (22.366388644627897 steps/sec)\n",
      "Step #21100\tEpoch   1 Batch 2349/3125   Loss: 0.777710 mae: 0.693216 (22.450630391989357 steps/sec)\n",
      "Step #21150\tEpoch   1 Batch 2399/3125   Loss: 0.705547 mae: 0.690851 (22.935653694762244 steps/sec)\n",
      "Step #21200\tEpoch   1 Batch 2449/3125   Loss: 0.739001 mae: 0.684307 (22.945465633914726 steps/sec)\n",
      "Step #21250\tEpoch   1 Batch 2499/3125   Loss: 0.919302 mae: 0.695758 (22.33273599103092 steps/sec)\n",
      "Step #21300\tEpoch   1 Batch 2549/3125   Loss: 0.610672 mae: 0.698173 (22.233172499951234 steps/sec)\n",
      "Step #21350\tEpoch   1 Batch 2599/3125   Loss: 0.907113 mae: 0.694851 (22.653022117555153 steps/sec)\n",
      "Step #21400\tEpoch   1 Batch 2649/3125   Loss: 0.859797 mae: 0.694430 (22.86415533154111 steps/sec)\n",
      "Step #21450\tEpoch   1 Batch 2699/3125   Loss: 0.766630 mae: 0.688782 (21.976998446735998 steps/sec)\n",
      "Step #21500\tEpoch   1 Batch 2749/3125   Loss: 0.876799 mae: 0.689055 (22.745715368145312 steps/sec)\n",
      "Step #21550\tEpoch   1 Batch 2799/3125   Loss: 0.793687 mae: 0.697990 (23.08754167868941 steps/sec)\n",
      "Step #21600\tEpoch   1 Batch 2849/3125   Loss: 0.768730 mae: 0.689525 (23.013728334562217 steps/sec)\n",
      "Step #21650\tEpoch   1 Batch 2899/3125   Loss: 0.819086 mae: 0.686882 (22.473230717661735 steps/sec)\n",
      "Step #21700\tEpoch   1 Batch 2949/3125   Loss: 0.826667 mae: 0.692326 (22.14177245714579 steps/sec)\n",
      "Step #21750\tEpoch   1 Batch 2999/3125   Loss: 0.719894 mae: 0.689763 (22.97685487952159 steps/sec)\n",
      "Step #21800\tEpoch   1 Batch 3049/3125   Loss: 0.752250 mae: 0.681552 (22.79407001500365 steps/sec)\n",
      "Step #21850\tEpoch   1 Batch 3099/3125   Loss: 0.837054 mae: 0.687517 (22.262701001324306 steps/sec)\n",
      "\n",
      "Train time for epoch #2 (21875 total steps): 139.80752801895142\n",
      "Model test set loss: 0.790732 mae: 0.701474\n",
      "best loss = 0.7907323241233826\n",
      "Step #21900\tEpoch   2 Batch   24/3125   Loss: 0.677470 mae: 0.701123 (49.008508447571124 steps/sec)\n",
      "Step #21950\tEpoch   2 Batch   74/3125   Loss: 0.823808 mae: 0.684358 (22.810539946278926 steps/sec)\n",
      "Step #22000\tEpoch   2 Batch  124/3125   Loss: 0.655782 mae: 0.692173 (21.62854323497477 steps/sec)\n",
      "Step #22050\tEpoch   2 Batch  174/3125   Loss: 0.752600 mae: 0.690546 (20.518889708149977 steps/sec)\n",
      "Step #22100\tEpoch   2 Batch  224/3125   Loss: 0.629831 mae: 0.692920 (21.084971908347246 steps/sec)\n",
      "Step #22150\tEpoch   2 Batch  274/3125   Loss: 0.766700 mae: 0.689751 (22.088504761902755 steps/sec)\n",
      "Step #22200\tEpoch   2 Batch  324/3125   Loss: 0.746647 mae: 0.693254 (20.88581713795611 steps/sec)\n",
      "Step #22250\tEpoch   2 Batch  374/3125   Loss: 0.772781 mae: 0.694670 (17.247795185063982 steps/sec)\n",
      "Step #22300\tEpoch   2 Batch  424/3125   Loss: 0.820837 mae: 0.694345 (19.225757751191257 steps/sec)\n",
      "Step #22350\tEpoch   2 Batch  474/3125   Loss: 0.768905 mae: 0.691524 (21.2857897861395 steps/sec)\n",
      "Step #22400\tEpoch   2 Batch  524/3125   Loss: 0.835199 mae: 0.684715 (21.96760134113118 steps/sec)\n",
      "Step #22450\tEpoch   2 Batch  574/3125   Loss: 0.815059 mae: 0.691184 (22.369373182420162 steps/sec)\n",
      "Step #22500\tEpoch   2 Batch  624/3125   Loss: 0.602520 mae: 0.689507 (21.870869852101272 steps/sec)\n",
      "Step #22550\tEpoch   2 Batch  674/3125   Loss: 0.783663 mae: 0.693095 (21.441320779601856 steps/sec)\n",
      "Step #22600\tEpoch   2 Batch  724/3125   Loss: 0.639632 mae: 0.691244 (21.255079768171218 steps/sec)\n",
      "Step #22650\tEpoch   2 Batch  774/3125   Loss: 0.716346 mae: 0.683321 (22.32297049195963 steps/sec)\n",
      "Step #22700\tEpoch   2 Batch  824/3125   Loss: 0.790627 mae: 0.691447 (22.274034245783852 steps/sec)\n",
      "Step #22750\tEpoch   2 Batch  874/3125   Loss: 0.708712 mae: 0.689064 (21.63093918093067 steps/sec)\n",
      "Step #22800\tEpoch   2 Batch  924/3125   Loss: 0.866511 mae: 0.695528 (21.655960977898683 steps/sec)\n",
      "Step #22850\tEpoch   2 Batch  974/3125   Loss: 0.721084 mae: 0.690579 (21.101142206460064 steps/sec)\n",
      "Step #22900\tEpoch   2 Batch 1024/3125   Loss: 0.751335 mae: 0.686627 (22.295818013821556 steps/sec)\n",
      "Step #22950\tEpoch   2 Batch 1074/3125   Loss: 0.793001 mae: 0.690462 (22.009529005029396 steps/sec)\n",
      "Step #23000\tEpoch   2 Batch 1124/3125   Loss: 0.759590 mae: 0.694365 (21.742200563846264 steps/sec)\n",
      "Step #23050\tEpoch   2 Batch 1174/3125   Loss: 0.700331 mae: 0.693871 (21.309213499084034 steps/sec)\n",
      "Step #23100\tEpoch   2 Batch 1224/3125   Loss: 0.740709 mae: 0.685019 (21.645078031714295 steps/sec)\n",
      "Step #23150\tEpoch   2 Batch 1274/3125   Loss: 0.866872 mae: 0.700083 (22.323555040446667 steps/sec)\n",
      "Step #23200\tEpoch   2 Batch 1324/3125   Loss: 0.682816 mae: 0.686566 (21.639159479158316 steps/sec)\n",
      "Step #23250\tEpoch   2 Batch 1374/3125   Loss: 0.714050 mae: 0.684394 (21.533642825781325 steps/sec)\n",
      "Step #23300\tEpoch   2 Batch 1424/3125   Loss: 0.759561 mae: 0.689584 (21.51465752932788 steps/sec)\n",
      "Step #23350\tEpoch   2 Batch 1474/3125   Loss: 0.696511 mae: 0.691748 (21.522259556468335 steps/sec)\n",
      "Step #23400\tEpoch   2 Batch 1524/3125   Loss: 0.688901 mae: 0.685080 (22.096254719215626 steps/sec)\n",
      "Step #23450\tEpoch   2 Batch 1574/3125   Loss: 0.741747 mae: 0.693253 (22.351982936558436 steps/sec)\n",
      "Step #23500\tEpoch   2 Batch 1624/3125   Loss: 0.806484 mae: 0.684300 (21.264424691470186 steps/sec)\n",
      "Step #23550\tEpoch   2 Batch 1674/3125   Loss: 0.679538 mae: 0.691065 (20.857145670287842 steps/sec)\n",
      "Step #23600\tEpoch   2 Batch 1724/3125   Loss: 0.867307 mae: 0.687099 (20.427982456781194 steps/sec)\n",
      "Step #23650\tEpoch   2 Batch 1774/3125   Loss: 0.737830 mae: 0.689134 (21.529424905224012 steps/sec)\n",
      "Step #23700\tEpoch   2 Batch 1824/3125   Loss: 0.700391 mae: 0.688996 (21.61904721651489 steps/sec)\n",
      "Step #23750\tEpoch   2 Batch 1874/3125   Loss: 0.819382 mae: 0.691319 (21.13341889547445 steps/sec)\n",
      "Step #23800\tEpoch   2 Batch 1924/3125   Loss: 0.942690 mae: 0.685384 (18.900782410442066 steps/sec)\n",
      "Step #23850\tEpoch   2 Batch 1974/3125   Loss: 0.761059 mae: 0.682493 (19.312543541011777 steps/sec)\n",
      "Step #23900\tEpoch   2 Batch 2024/3125   Loss: 0.852022 mae: 0.693065 (19.733820686677777 steps/sec)\n",
      "Step #23950\tEpoch   2 Batch 2074/3125   Loss: 0.795773 mae: 0.683071 (20.35586895691935 steps/sec)\n",
      "Step #24000\tEpoch   2 Batch 2124/3125   Loss: 0.633055 mae: 0.685349 (21.256919654667495 steps/sec)\n",
      "Step #24050\tEpoch   2 Batch 2174/3125   Loss: 0.716637 mae: 0.681141 (21.580000483636866 steps/sec)\n",
      "Step #24100\tEpoch   2 Batch 2224/3125   Loss: 0.688394 mae: 0.684861 (21.47636490993791 steps/sec)\n",
      "Step #24150\tEpoch   2 Batch 2274/3125   Loss: 0.781351 mae: 0.686685 (21.103503420743674 steps/sec)\n",
      "Step #24200\tEpoch   2 Batch 2324/3125   Loss: 0.631408 mae: 0.695233 (20.486043783034038 steps/sec)\n",
      "Step #24250\tEpoch   2 Batch 2374/3125   Loss: 0.726018 mae: 0.685501 (21.257725513219786 steps/sec)\n",
      "Step #24300\tEpoch   2 Batch 2424/3125   Loss: 0.708038 mae: 0.685984 (21.443598680593396 steps/sec)\n",
      "Step #24350\tEpoch   2 Batch 2474/3125   Loss: 0.817172 mae: 0.681560 (21.587015460926576 steps/sec)\n",
      "Step #24400\tEpoch   2 Batch 2524/3125   Loss: 0.743497 mae: 0.692212 (20.594547112381413 steps/sec)\n",
      "Step #24450\tEpoch   2 Batch 2574/3125   Loss: 0.827700 mae: 0.696201 (20.460724159573495 steps/sec)\n",
      "Step #24500\tEpoch   2 Batch 2624/3125   Loss: 0.951360 mae: 0.692954 (21.618732980476306 steps/sec)\n",
      "Step #24550\tEpoch   2 Batch 2674/3125   Loss: 0.750745 mae: 0.689713 (21.50276075641988 steps/sec)\n",
      "Step #24600\tEpoch   2 Batch 2724/3125   Loss: 0.727575 mae: 0.680992 (21.330128519711952 steps/sec)\n",
      "Step #24650\tEpoch   2 Batch 2774/3125   Loss: 0.685520 mae: 0.689033 (20.873699581650513 steps/sec)\n",
      "Step #24700\tEpoch   2 Batch 2824/3125   Loss: 0.780420 mae: 0.697939 (21.629167825226713 steps/sec)\n",
      "Step #24750\tEpoch   2 Batch 2874/3125   Loss: 0.791494 mae: 0.677814 (20.98438552676646 steps/sec)\n",
      "Step #24800\tEpoch   2 Batch 2924/3125   Loss: 0.781951 mae: 0.685306 (20.476126732667854 steps/sec)\n",
      "Step #24850\tEpoch   2 Batch 2974/3125   Loss: 0.690315 mae: 0.688727 (20.133323438606887 steps/sec)\n",
      "Step #24900\tEpoch   2 Batch 3024/3125   Loss: 0.708363 mae: 0.679735 (21.54309935785261 steps/sec)\n",
      "Step #24950\tEpoch   2 Batch 3074/3125   Loss: 0.746624 mae: 0.681130 (21.51837948898117 steps/sec)\n",
      "Step #25000\tEpoch   2 Batch 3124/3125   Loss: 0.810080 mae: 0.681745 (20.718474906726694 steps/sec)\n",
      "\n",
      "Train time for epoch #3 (25000 total steps): 147.65214204788208\n",
      "Model test set loss: 0.784764 mae: 0.698979\n",
      "best loss = 0.7847635746002197\n",
      "Step #25050\tEpoch   3 Batch   49/3125   Loss: 0.825477 mae: 0.698260 (23.81129288787681 steps/sec)\n",
      "Step #25100\tEpoch   3 Batch   99/3125   Loss: 0.919461 mae: 0.678097 (21.84415238384508 steps/sec)\n",
      "Step #25150\tEpoch   3 Batch  149/3125   Loss: 0.720782 mae: 0.687250 (20.41892269510244 steps/sec)\n",
      "Step #25200\tEpoch   3 Batch  199/3125   Loss: 0.766610 mae: 0.687465 (20.133211333187603 steps/sec)\n",
      "Step #25250\tEpoch   3 Batch  249/3125   Loss: 0.838144 mae: 0.686725 (20.035698600478433 steps/sec)\n",
      "Step #25300\tEpoch   3 Batch  299/3125   Loss: 0.752909 mae: 0.687139 (20.048083233379007 steps/sec)\n",
      "Step #25350\tEpoch   3 Batch  349/3125   Loss: 0.833256 mae: 0.690154 (19.735987946580238 steps/sec)\n",
      "Step #25400\tEpoch   3 Batch  399/3125   Loss: 0.886335 mae: 0.690693 (20.77749147362272 steps/sec)\n",
      "Step #25450\tEpoch   3 Batch  449/3125   Loss: 0.766616 mae: 0.691303 (20.784255932474004 steps/sec)\n",
      "Step #25500\tEpoch   3 Batch  499/3125   Loss: 0.757955 mae: 0.681329 (20.476544583101603 steps/sec)\n",
      "Step #25550\tEpoch   3 Batch  549/3125   Loss: 0.750976 mae: 0.678682 (20.028913274787946 steps/sec)\n",
      "Step #25600\tEpoch   3 Batch  599/3125   Loss: 0.674053 mae: 0.691284 (20.71055254060164 steps/sec)\n",
      "Step #25650\tEpoch   3 Batch  649/3125   Loss: 0.720236 mae: 0.688521 (20.917763439736223 steps/sec)\n",
      "Step #25700\tEpoch   3 Batch  699/3125   Loss: 0.764091 mae: 0.687948 (19.344327408113493 steps/sec)\n",
      "Step #25750\tEpoch   3 Batch  749/3125   Loss: 0.726226 mae: 0.677676 (19.60584176212798 steps/sec)\n",
      "Step #25800\tEpoch   3 Batch  799/3125   Loss: 0.796776 mae: 0.686773 (20.800358013974606 steps/sec)\n",
      "Step #25850\tEpoch   3 Batch  849/3125   Loss: 0.842788 mae: 0.687256 (20.771961686877994 steps/sec)\n",
      "Step #25900\tEpoch   3 Batch  899/3125   Loss: 0.798348 mae: 0.685474 (20.11448407402246 steps/sec)\n",
      "Step #25950\tEpoch   3 Batch  949/3125   Loss: 0.649633 mae: 0.687289 (19.727653936745703 steps/sec)\n",
      "Step #26000\tEpoch   3 Batch  999/3125   Loss: 0.822290 mae: 0.681371 (20.266454114642414 steps/sec)\n",
      "Step #26050\tEpoch   3 Batch 1049/3125   Loss: 0.827456 mae: 0.691943 (20.748241943968374 steps/sec)\n",
      "Step #26100\tEpoch   3 Batch 1099/3125   Loss: 0.725467 mae: 0.684415 (20.052858448746047 steps/sec)\n",
      "Step #26150\tEpoch   3 Batch 1149/3125   Loss: 0.687811 mae: 0.693950 (19.991988531512316 steps/sec)\n",
      "Step #26200\tEpoch   3 Batch 1199/3125   Loss: 0.812134 mae: 0.681074 (19.95706069504348 steps/sec)\n",
      "Step #26250\tEpoch   3 Batch 1249/3125   Loss: 0.859826 mae: 0.688411 (19.90843731897878 steps/sec)\n",
      "Step #26300\tEpoch   3 Batch 1299/3125   Loss: 0.730778 mae: 0.695306 (19.299253218126584 steps/sec)\n",
      "Step #26350\tEpoch   3 Batch 1349/3125   Loss: 0.774963 mae: 0.673812 (20.60633656404564 steps/sec)\n",
      "Step #26400\tEpoch   3 Batch 1399/3125   Loss: 0.773205 mae: 0.688188 (20.770243874707756 steps/sec)\n",
      "Step #26450\tEpoch   3 Batch 1449/3125   Loss: 0.740591 mae: 0.687270 (20.202567842521177 steps/sec)\n",
      "Step #26500\tEpoch   3 Batch 1499/3125   Loss: 0.775160 mae: 0.686701 (19.25737307882141 steps/sec)\n",
      "Step #26550\tEpoch   3 Batch 1549/3125   Loss: 0.852619 mae: 0.684470 (19.806959889799305 steps/sec)\n",
      "Step #26600\tEpoch   3 Batch 1599/3125   Loss: 0.745724 mae: 0.682293 (20.30051293558118 steps/sec)\n",
      "Step #26650\tEpoch   3 Batch 1649/3125   Loss: 0.809010 mae: 0.687630 (20.86629336916862 steps/sec)\n",
      "Step #26700\tEpoch   3 Batch 1699/3125   Loss: 0.796155 mae: 0.682176 (20.39907106815004 steps/sec)\n",
      "Step #26750\tEpoch   3 Batch 1749/3125   Loss: 0.756090 mae: 0.681904 (19.089506547899767 steps/sec)\n",
      "Step #26800\tEpoch   3 Batch 1799/3125   Loss: 0.833763 mae: 0.685718 (19.80911143635875 steps/sec)\n",
      "Step #26850\tEpoch   3 Batch 1849/3125   Loss: 0.746721 mae: 0.687116 (19.89909602786089 steps/sec)\n",
      "Step #26900\tEpoch   3 Batch 1899/3125   Loss: 0.852258 mae: 0.684189 (20.093710195156437 steps/sec)\n",
      "Step #26950\tEpoch   3 Batch 1949/3125   Loss: 0.725373 mae: 0.677203 (19.115577145588524 steps/sec)\n",
      "Step #27000\tEpoch   3 Batch 1999/3125   Loss: 0.859528 mae: 0.684964 (19.91018187207273 steps/sec)\n",
      "Step #27050\tEpoch   3 Batch 2049/3125   Loss: 0.704912 mae: 0.692974 (20.76179884136373 steps/sec)\n",
      "Step #27100\tEpoch   3 Batch 2099/3125   Loss: 0.811308 mae: 0.674576 (20.104530227994925 steps/sec)\n",
      "Step #27150\tEpoch   3 Batch 2149/3125   Loss: 0.735906 mae: 0.675294 (19.253140618804522 steps/sec)\n",
      "Step #27200\tEpoch   3 Batch 2199/3125   Loss: 0.675465 mae: 0.679566 (20.015306734533713 steps/sec)\n",
      "Step #27250\tEpoch   3 Batch 2249/3125   Loss: 0.709298 mae: 0.678840 (20.04238509076956 steps/sec)\n",
      "Step #27300\tEpoch   3 Batch 2299/3125   Loss: 0.805228 mae: 0.693338 (20.52955763037747 steps/sec)\n",
      "Step #27350\tEpoch   3 Batch 2349/3125   Loss: 0.752954 mae: 0.684425 (19.856556482601114 steps/sec)\n",
      "Step #27400\tEpoch   3 Batch 2399/3125   Loss: 0.685730 mae: 0.682620 (19.697673429106995 steps/sec)\n",
      "Step #27450\tEpoch   3 Batch 2449/3125   Loss: 0.725444 mae: 0.676639 (20.020655006968056 steps/sec)\n",
      "Step #27500\tEpoch   3 Batch 2499/3125   Loss: 0.894898 mae: 0.686778 (19.948229677751478 steps/sec)\n",
      "Step #27550\tEpoch   3 Batch 2549/3125   Loss: 0.594983 mae: 0.689495 (19.68601902074176 steps/sec)\n",
      "Step #27600\tEpoch   3 Batch 2599/3125   Loss: 0.882799 mae: 0.687733 (19.37656337529498 steps/sec)\n",
      "Step #27650\tEpoch   3 Batch 2649/3125   Loss: 0.847576 mae: 0.686600 (20.709979877125743 steps/sec)\n",
      "Step #27700\tEpoch   3 Batch 2699/3125   Loss: 0.767826 mae: 0.682383 (20.768993239326036 steps/sec)\n",
      "Step #27750\tEpoch   3 Batch 2749/3125   Loss: 0.838857 mae: 0.680452 (19.86464979465211 steps/sec)\n",
      "Step #27800\tEpoch   3 Batch 2799/3125   Loss: 0.767464 mae: 0.690124 (19.435447204380658 steps/sec)\n",
      "Step #27850\tEpoch   3 Batch 2849/3125   Loss: 0.769663 mae: 0.682462 (20.01849548189436 steps/sec)\n",
      "Step #27900\tEpoch   3 Batch 2899/3125   Loss: 0.818842 mae: 0.678601 (20.02092641386948 steps/sec)\n",
      "Step #27950\tEpoch   3 Batch 2949/3125   Loss: 0.810463 mae: 0.684037 (19.88397965173416 steps/sec)\n",
      "Step #28000\tEpoch   3 Batch 2999/3125   Loss: 0.701442 mae: 0.681425 (18.830369523482517 steps/sec)\n",
      "Step #28050\tEpoch   3 Batch 3049/3125   Loss: 0.740438 mae: 0.674180 (19.232004431202192 steps/sec)\n",
      "Step #28100\tEpoch   3 Batch 3099/3125   Loss: 0.816523 mae: 0.678290 (19.878811547453786 steps/sec)\n",
      "\n",
      "Train time for epoch #4 (28125 total steps): 155.66709995269775\n",
      "Model test set loss: 0.779415 mae: 0.695759\n",
      "best loss = 0.779415488243103\n",
      "Step #28150\tEpoch   4 Batch   24/3125   Loss: 0.668980 mae: 0.695321 (47.62448915820903 steps/sec)\n",
      "Step #28200\tEpoch   4 Batch   74/3125   Loss: 0.805731 mae: 0.676488 (21.518169735784852 steps/sec)\n",
      "Step #28250\tEpoch   4 Batch  124/3125   Loss: 0.645950 mae: 0.684444 (20.37148602764998 steps/sec)\n",
      "Step #28300\tEpoch   4 Batch  174/3125   Loss: 0.746838 mae: 0.681452 (19.856280113648843 steps/sec)\n",
      "Step #28350\tEpoch   4 Batch  224/3125   Loss: 0.624850 mae: 0.685194 (19.836459911074403 steps/sec)\n",
      "Step #28400\tEpoch   4 Batch  274/3125   Loss: 0.752358 mae: 0.682538 (19.22381916143107 steps/sec)\n",
      "Step #28450\tEpoch   4 Batch  324/3125   Loss: 0.737046 mae: 0.684622 (19.231789264945878 steps/sec)\n",
      "Step #28500\tEpoch   4 Batch  374/3125   Loss: 0.734166 mae: 0.686590 (19.2174791793659 steps/sec)\n",
      "Step #28550\tEpoch   4 Batch  424/3125   Loss: 0.809108 mae: 0.687314 (19.734617336145853 steps/sec)\n",
      "Step #28600\tEpoch   4 Batch  474/3125   Loss: 0.758181 mae: 0.682952 (19.351478112314776 steps/sec)\n",
      "Step #28650\tEpoch   4 Batch  524/3125   Loss: 0.838118 mae: 0.674855 (20.17897074501865 steps/sec)\n",
      "Step #28700\tEpoch   4 Batch  574/3125   Loss: 0.794978 mae: 0.681038 (20.809707873517105 steps/sec)\n",
      "Step #28750\tEpoch   4 Batch  624/3125   Loss: 0.595854 mae: 0.681034 (19.834161730238257 steps/sec)\n",
      "Step #28800\tEpoch   4 Batch  674/3125   Loss: 0.771374 mae: 0.684776 (19.335926821264806 steps/sec)\n",
      "Step #28850\tEpoch   4 Batch  724/3125   Loss: 0.624865 mae: 0.682921 (20.019586652705204 steps/sec)\n",
      "Step #28900\tEpoch   4 Batch  774/3125   Loss: 0.700449 mae: 0.676213 (19.78482052921172 steps/sec)\n",
      "Step #28950\tEpoch   4 Batch  824/3125   Loss: 0.781870 mae: 0.683432 (19.299221249580476 steps/sec)\n",
      "Step #29000\tEpoch   4 Batch  874/3125   Loss: 0.684071 mae: 0.682361 (19.92669370558805 steps/sec)\n",
      "Step #29050\tEpoch   4 Batch  924/3125   Loss: 0.839394 mae: 0.687952 (19.9183359925598 steps/sec)\n",
      "Step #29100\tEpoch   4 Batch  974/3125   Loss: 0.714656 mae: 0.681904 (19.353215713930556 steps/sec)\n",
      "Step #29150\tEpoch   4 Batch 1024/3125   Loss: 0.737321 mae: 0.678475 (19.98676794594948 steps/sec)\n",
      "Step #29200\tEpoch   4 Batch 1074/3125   Loss: 0.765512 mae: 0.682827 (20.005114909465053 steps/sec)\n",
      "Step #29250\tEpoch   4 Batch 1124/3125   Loss: 0.740862 mae: 0.686439 (19.468790272734548 steps/sec)\n",
      "Step #29300\tEpoch   4 Batch 1174/3125   Loss: 0.657998 mae: 0.685746 (18.581363861857884 steps/sec)\n",
      "Step #29350\tEpoch   4 Batch 1224/3125   Loss: 0.728057 mae: 0.677262 (19.632655361498333 steps/sec)\n",
      "Step #29400\tEpoch   4 Batch 1274/3125   Loss: 0.846793 mae: 0.690993 (20.07797386663409 steps/sec)\n",
      "Step #29450\tEpoch   4 Batch 1324/3125   Loss: 0.664076 mae: 0.681344 (19.95784888064282 steps/sec)\n",
      "Step #29500\tEpoch   4 Batch 1374/3125   Loss: 0.704675 mae: 0.677058 (19.537677221464808 steps/sec)\n",
      "Step #29550\tEpoch   4 Batch 1424/3125   Loss: 0.738769 mae: 0.682327 (19.73728815952069 steps/sec)\n",
      "Step #29600\tEpoch   4 Batch 1474/3125   Loss: 0.687385 mae: 0.683243 (19.858763950196657 steps/sec)\n",
      "Step #29650\tEpoch   4 Batch 1524/3125   Loss: 0.681630 mae: 0.677053 (20.030374812115426 steps/sec)\n",
      "Step #29700\tEpoch   4 Batch 1574/3125   Loss: 0.724354 mae: 0.684595 (19.35892360001141 steps/sec)\n",
      "Step #29750\tEpoch   4 Batch 1624/3125   Loss: 0.788827 mae: 0.676558 (19.672438706549762 steps/sec)\n",
      "Step #29800\tEpoch   4 Batch 1674/3125   Loss: 0.665080 mae: 0.683241 (20.010912170008478 steps/sec)\n",
      "Step #29850\tEpoch   4 Batch 1724/3125   Loss: 0.859088 mae: 0.679337 (19.906645831858082 steps/sec)\n",
      "Step #29900\tEpoch   4 Batch 1774/3125   Loss: 0.713818 mae: 0.682265 (20.011126028513548 steps/sec)\n",
      "Step #29950\tEpoch   4 Batch 1824/3125   Loss: 0.676466 mae: 0.681535 (19.291239532823408 steps/sec)\n",
      "Step #30000\tEpoch   4 Batch 1874/3125   Loss: 0.788242 mae: 0.683325 (20.201775777890205 steps/sec)\n",
      "Step #30050\tEpoch   4 Batch 1924/3125   Loss: 0.923507 mae: 0.677603 (20.072154980644264 steps/sec)\n",
      "Step #30100\tEpoch   4 Batch 1974/3125   Loss: 0.743590 mae: 0.674824 (19.895501637204262 steps/sec)\n",
      "Step #30150\tEpoch   4 Batch 2024/3125   Loss: 0.859466 mae: 0.686711 (18.538127521404814 steps/sec)\n",
      "Step #30200\tEpoch   4 Batch 2074/3125   Loss: 0.780843 mae: 0.674699 (19.284225479061487 steps/sec)\n",
      "Step #30250\tEpoch   4 Batch 2124/3125   Loss: 0.623795 mae: 0.678678 (19.975844030160673 steps/sec)\n",
      "Step #30300\tEpoch   4 Batch 2174/3125   Loss: 0.704396 mae: 0.672166 (19.69399607669941 steps/sec)\n",
      "Step #30350\tEpoch   4 Batch 2224/3125   Loss: 0.677674 mae: 0.677781 (19.206604028551933 steps/sec)\n",
      "Step #30400\tEpoch   4 Batch 2274/3125   Loss: 0.769912 mae: 0.677814 (20.01004723536436 steps/sec)\n",
      "Step #30450\tEpoch   4 Batch 2324/3125   Loss: 0.615607 mae: 0.687302 (19.561762464472835 steps/sec)\n",
      "Step #30500\tEpoch   4 Batch 2374/3125   Loss: 0.697032 mae: 0.677838 (18.50661309756717 steps/sec)\n",
      "Step #30550\tEpoch   4 Batch 2424/3125   Loss: 0.698104 mae: 0.677791 (19.004881553433602 steps/sec)\n",
      "Step #30600\tEpoch   4 Batch 2474/3125   Loss: 0.802682 mae: 0.673504 (19.515926568482396 steps/sec)\n",
      "Step #30650\tEpoch   4 Batch 2524/3125   Loss: 0.721797 mae: 0.683670 (19.94179547781006 steps/sec)\n",
      "Step #30700\tEpoch   4 Batch 2574/3125   Loss: 0.795780 mae: 0.688207 (19.860294799356904 steps/sec)\n",
      "Step #30750\tEpoch   4 Batch 2624/3125   Loss: 0.945477 mae: 0.684643 (19.04690111578414 steps/sec)\n",
      "Step #30800\tEpoch   4 Batch 2674/3125   Loss: 0.751700 mae: 0.681883 (19.990212464257098 steps/sec)\n",
      "Step #30850\tEpoch   4 Batch 2724/3125   Loss: 0.696729 mae: 0.673727 (19.47977264656677 steps/sec)\n",
      "Step #30900\tEpoch   4 Batch 2774/3125   Loss: 0.660515 mae: 0.680830 (18.839644650943846 steps/sec)\n",
      "Step #30950\tEpoch   4 Batch 2824/3125   Loss: 0.775812 mae: 0.689861 (19.40762989398668 steps/sec)\n",
      "Step #31000\tEpoch   4 Batch 2874/3125   Loss: 0.785366 mae: 0.671317 (19.71572122204545 steps/sec)\n",
      "Step #31050\tEpoch   4 Batch 2924/3125   Loss: 0.785085 mae: 0.677810 (19.6236940475179 steps/sec)\n",
      "Step #31100\tEpoch   4 Batch 2974/3125   Loss: 0.660961 mae: 0.681325 (19.668663777636596 steps/sec)\n",
      "Step #31150\tEpoch   4 Batch 3024/3125   Loss: 0.681954 mae: 0.671087 (19.31819898531997 steps/sec)\n",
      "Step #31200\tEpoch   4 Batch 3074/3125   Loss: 0.731474 mae: 0.672183 (19.525187808078986 steps/sec)\n",
      "Step #31250\tEpoch   4 Batch 3124/3125   Loss: 0.797118 mae: 0.673330 (20.144079765158377 steps/sec)\n",
      "\n",
      "Train time for epoch #5 (31250 total steps): 158.92730712890625\n",
      "Model test set loss: 0.774648 mae: 0.693670\n",
      "best loss = 0.7746484279632568\n",
      "WARNING:tensorflow:From /Users/xulei/opt/miniconda3/envs/pyml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./models/export/assets\n"
     ]
    }
   ],
   "source": [
    "mrs_net = mrs_network()\n",
    "mrs_net.training(features, targets_values, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(mrs_net.losses['train'], label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Testing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mrs_net.losses['test'], label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate Given User and Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_movie(mrs_net, user_id_val, movie_id_val):\n",
    "    categories = np.zeros([1, 18])\n",
    "    categories[0] = movies.values[movieid2idx[movie_id_val]][2]\n",
    "    \n",
    "    titles = np.zeros([1, sentences_size])\n",
    "    titles[0] = movies.values[movieid2idx[movie_id_val]][1]\n",
    "    \n",
    "    inference_val = mrs_net.model([np.reshape(users.values[user_id_val-1][0], [1, 1]),\n",
    "              np.reshape(users.values[user_id_val-1][1], [1, 1]),\n",
    "              np.reshape(users.values[user_id_val-1][2], [1, 1]),\n",
    "              np.reshape(users.values[user_id_val-1][3], [1, 1]),\n",
    "              np.reshape(movies.values[movieid2idx[movie_id_val]][0], [1, 1]),\n",
    "              categories,  \n",
    "              titles])\n",
    "\n",
    "    return (inference_val.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save User's Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_layer_model = keras.models.Model(inputs=[mrs_net.model.input[0], mrs_net.model.input[1], mrs_net.model.input[2], mrs_net.model.input[3]], \n",
    "                                 outputs=mrs_net.model.get_layer(\"user_combine_layer_flat\").output)\n",
    "users_matrics = []\n",
    "\n",
    "for item in users.values:\n",
    "    user_combine_layer_flat_val = user_layer_model([np.reshape(item.take(0), [1, 1]), \n",
    "                                                    np.reshape(item.take(1), [1, 1]), \n",
    "                                                    np.reshape(item.take(2), [1, 1]), \n",
    "                                                    np.reshape(item.take(3), [1, 1])])  \n",
    "    users_matrics.append(user_combine_layer_flat_val)\n",
    "\n",
    "pickle.dump((np.array(users_matrics).reshape(-1, 200)), open('users_matrics.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08721562 -0.00709821 -0.06595337 ... -0.06491411 -0.02668362\n",
      "  -0.03354005]\n",
      " [ 0.07009808 -0.02590186 -0.01503292 ... -0.06701663 -0.05415995\n",
      "  -0.03795098]\n",
      " [ 0.08229617 -0.02549316 -0.02290676 ... -0.08154348 -0.00164201\n",
      "  -0.04060952]\n",
      " ...\n",
      " [ 0.05604266 -0.01856662 -0.01040919 ... -0.08118518 -0.04427848\n",
      "   0.01328425]\n",
      " [ 0.04317714 -0.03529676 -0.0363038  ... -0.07984999 -0.03262015\n",
      "  -0.01353997]\n",
      " [ 0.08058929 -0.06454856  0.02958072 ... -0.04606372 -0.08905683\n",
      "   0.04742653]]\n"
     ]
    }
   ],
   "source": [
    "users_matrics = pickle.load(open('users_matrics.pkl', mode='rb'))\n",
    "print(users_matrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Movie's Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_layer_model = keras.models.Model(inputs=[mrs_net.model.input[4], mrs_net.model.input[5], mrs_net.model.input[6]], \n",
    "                                 outputs=mrs_net.model.get_layer(\"movie_combine_layer_flat\").output)\n",
    "movie_matrics = []\n",
    "\n",
    "for item in movies.values:\n",
    "    categories = np.zeros([1, 18])\n",
    "    categories[0] = item.take(2)\n",
    "\n",
    "    titles = np.zeros([1, sentences_size])\n",
    "    titles[0] = item.take(1)\n",
    "\n",
    "    movie_combine_layer_flat_val = movie_layer_model([np.reshape(item.take(0), [1, 1]), categories, titles])  \n",
    "    movie_matrics.append(movie_combine_layer_flat_val)\n",
    "\n",
    "pickle.dump((np.array(movie_matrics).reshape(-1, 200)), open('movie_matrics.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.88726270e-01 -4.80105020e-02  2.03469973e-02 ... -3.33199054e-01\n",
      "  -4.73684579e-01 -2.71819503e-04]\n",
      " [ 6.84157789e-01  1.94017425e-01 -1.91081032e-01 ... -2.46648043e-01\n",
      "  -3.20044398e-01 -2.75782961e-02]\n",
      " [ 6.78753614e-01  1.75881878e-01 -3.63804936e-01 ... -1.20301776e-01\n",
      "  -3.28855187e-01 -5.35191186e-02]\n",
      " ...\n",
      " [ 7.59305418e-01 -3.21341418e-02 -3.52758123e-03 ... -2.44071230e-01\n",
      "  -5.12492120e-01  1.00438938e-01]\n",
      " [ 7.80881226e-01 -8.19373131e-03  3.49915214e-02 ... -2.48205215e-01\n",
      "  -5.67351878e-01  2.17452675e-01]\n",
      " [ 7.65495062e-01 -1.02245837e-01  1.11058727e-01 ... -3.44492108e-01\n",
      "  -5.10848165e-01  1.44482061e-01]]\n"
     ]
    }
   ],
   "source": [
    "movie_matrics = pickle.load(open('movie_matrics.pkl', mode='rb'))\n",
    "print(movie_matrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend Movie\n",
    "\n",
    "#### Recommend movies with same genre\n",
    "\n",
    "The ides is to \n",
    "\n",
    "1. Compute the **cosine similarity** of the given movie and the whole movies' feature matrix\n",
    "2. Return top k max similarity values\n",
    "3. Select randomly to make sure each recommendation id distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.38742164e-01  1.48341656e-01  1.48611948e-01 ...  1.46916345e-01\n",
      "   1.42074883e-01  1.42401546e-01]\n",
      " [-8.44536442e-03  4.20675837e-02  3.85090373e-02 ... -6.21756492e-03\n",
      "  -1.49078167e-03 -1.90203246e-02]\n",
      " [ 3.57917114e-03 -4.14309055e-02 -7.96544701e-02 ... -6.82544021e-04\n",
      "   6.36641821e-03  2.06597466e-02]\n",
      " ...\n",
      " [-5.86119145e-02 -5.34791537e-02 -2.63398681e-02 ... -4.72248122e-02\n",
      "  -4.51588891e-02 -6.40842915e-02]\n",
      " [-8.33242461e-02 -6.93932250e-02 -7.20022842e-02 ... -9.91609842e-02\n",
      "  -1.03224985e-01 -9.50307474e-02]\n",
      " [-4.78148468e-05 -5.97962923e-03 -1.17179193e-02 ...  1.94337107e-02\n",
      "   3.95637192e-02  2.68773362e-02]], shape=(200, 3883), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# print(movieid2idx)\n",
    "# print(tf.reshape(movie_matrics[movieid2idx[2]], [1, 200]))\n",
    "norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keepdims=True))\n",
    "normalized_movie_matrics = movie_matrics / norm_movie_matrics\n",
    "print(tf.transpose(normalized_movie_matrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_same_genre_movie(movie_id_val, top_k = 20):\n",
    "   \n",
    "    norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keepdims=True))\n",
    "    normalized_movie_matrics = movie_matrics / norm_movie_matrics\n",
    "\n",
    "    # Recommend movies with same genre\n",
    "    probs_embeddings = tf.reshape(movie_matrics[movieid2idx[movie_id_val]], [1, 200])\n",
    "    probs_similarity = tf.matmul(probs_embeddings, tf.transpose(normalized_movie_matrics))\n",
    "    sim = (probs_similarity.numpy())\n",
    "\n",
    "    print(f\"The movie you're watching is：{ movies_origin[movieid2idx[movie_id_val]] }\")\n",
    "    print(\"Here are recommendations for you：\")\n",
    "    p = np.squeeze(sim)\n",
    "    p[np.argsort(p)[:-top_k]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    results = set()\n",
    "    while len(results) != 5:\n",
    "        c = np.random.choice(3883, 1, p=p)[0]\n",
    "        results.add(c)\n",
    "    for val in (results):\n",
    "        print(val)\n",
    "        print(movies_origin[val])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie you're watching is：[1 'Toy Story (1995)' \"Animation|Children's|Comedy\"]\n",
      "Here are recommendations for you：\n",
      "3045\n",
      "[3114 'Toy Story 2 (1999)' \"Animation|Children's|Comedy\"]\n",
      "687\n",
      "[696 'Butterfly Kiss (1995)' 'Thriller']\n",
      "1010\n",
      "[1023 'Winnie the Pooh and the Blustery Day (1968)' \"Animation|Children's\"]\n",
      "1242\n",
      "[1262 'Great Escape, The (1963)' 'Adventure|War']\n",
      "3164\n",
      "[3233 'Smashing Time (1967)' 'Comedy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{687, 1010, 1242, 3045, 3164}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_same_genre_movie(1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommend movies you may like\n",
    "\n",
    "1. Compute the **cosine similarity** of the given user and the whole movies' feature matrix\n",
    "2. Return top k max similarity values\n",
    "3. Select randomly to make sure each recommendation id distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_your_favorite_movie(user_id_val, top_k = 10):\n",
    "    # Recommend your favorite movies\n",
    "    probs_embeddings = tf.reshape(users_matrics[user_id_val-1], [1, 200])\n",
    "    probs_similarity = tf.matmul(probs_embeddings, tf.transpose(movie_matrics))\n",
    "    sim = (probs_similarity.numpy())\n",
    "    \n",
    "    print(\"Here are recommendations for you：\")\n",
    "    p = np.squeeze(sim)\n",
    "    p[np.argsort(p)[:-top_k]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    results = set()\n",
    "    while len(results) != 5:\n",
    "        c = np.random.choice(3883, 1, p=p)[0]\n",
    "        results.add(c)\n",
    "    for val in (results):\n",
    "        print(val)\n",
    "        print(movies_origin[val])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are recommendations for you：\n",
      "2434\n",
      "[2503 'Apple, The (Sib) (1998)' 'Drama']\n",
      "553\n",
      "[557 'Mamma Roma (1962)' 'Drama']\n",
      "777\n",
      "[787 'Gate of Heavenly Peace, The (1995)' 'Documentary']\n",
      "847\n",
      "[858 'Godfather, The (1972)' 'Action|Crime|Drama']\n",
      "2128\n",
      "[2197 'Firelight (1997)' 'Drama']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{553, 777, 847, 2128, 2434}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_your_favorite_movie(2434, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommend other favorite movies according to the given movie\n",
    "\n",
    "1. Select top k users who like the given movie in order to obtain their feature matrix\n",
    "2. Calculate rating of all movies given by these users\n",
    "3. Recommend movies with highest ratings\n",
    "4. Select movies with same ratings randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def recommend_other_favorite_movie(movie_id_val, top_k = 20):\n",
    "    probs_movie_embeddings = tf.reshape(movie_matrics[movieid2idx[movie_id_val]], [1, 200])\n",
    "    probs_user_favorite_similarity = tf.matmul(probs_movie_embeddings, tf.transpose(users_matrics))\n",
    "    favorite_user_id = np.argsort(probs_user_favorite_similarity.numpy())[0][-top_k:]\n",
    "    \n",
    "    print(f\"The movie you watching is：{ movies_origin[movieid2idx[movie_id_val]] }\")\n",
    "    print(f\"People who like the movie are：{ users_origin[favorite_user_id - 1] }\")\n",
    "    \n",
    "    probs_users_embeddings = tf.reshape(users_matrics[favorite_user_id-1], [-1, 200])\n",
    "    probs_similarity = tf.matmul(probs_users_embeddings, tf.transpose(movie_matrics))\n",
    "    sim = (probs_similarity.numpy())\n",
    "    p = np.argmax(sim, 1)\n",
    "    print(\"Other movies may like：\")\n",
    "\n",
    "    if len(set(p)) < 5:\n",
    "        results = set(p)\n",
    "    else:\n",
    "        results = set()\n",
    "        while len(results) != 5:\n",
    "            c = p[random.randrange(top_k)]\n",
    "            results.add(c)\n",
    "    for val in (results):\n",
    "        print(val)\n",
    "        print(movies_origin[val])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12219557  0.01931428 -0.08634561 ... -0.06979283 -0.05957483\n",
      "  -0.00414855]\n",
      " [ 0.08322193 -0.03158041 -0.00214276 ... -0.08756841 -0.02978628\n",
      "  -0.10945226]\n",
      " [ 0.10401005 -0.01453629 -0.05497382 ... -0.09996834  0.01604793\n",
      "  -0.10561478]\n",
      " ...\n",
      " [ 0.07107168  0.00160648 -0.00643443 ... -0.10255556 -0.0314489\n",
      "  -0.02352512]\n",
      " [ 0.05907631 -0.00408916 -0.01036352 ... -0.09305456 -0.03401312\n",
      "  -0.02069971]\n",
      " [ 0.09105983 -0.06977449  0.02089941 ... -0.03242641 -0.1046113\n",
      "   0.04004176]]\n",
      "[[ 7.88726270e-01 -4.80105020e-02  2.03469973e-02 ... -3.33199054e-01\n",
      "  -4.73684579e-01 -2.71819503e-04]\n",
      " [ 6.84157789e-01  1.94017425e-01 -1.91081032e-01 ... -2.46648043e-01\n",
      "  -3.20044398e-01 -2.75782961e-02]\n",
      " [ 6.78753614e-01  1.75881878e-01 -3.63804936e-01 ... -1.20301776e-01\n",
      "  -3.28855187e-01 -5.35191186e-02]\n",
      " ...\n",
      " [ 7.59305418e-01 -3.21341418e-02 -3.52758123e-03 ... -2.44071230e-01\n",
      "  -5.12492120e-01  1.00438938e-01]\n",
      " [ 7.80881226e-01 -8.19373131e-03  3.49915214e-02 ... -2.48205215e-01\n",
      "  -5.67351878e-01  2.17452675e-01]\n",
      " [ 7.65495062e-01 -1.02245837e-01  1.11058727e-01 ... -3.44492108e-01\n",
      "  -5.10848165e-01  1.44482061e-01]]\n"
     ]
    }
   ],
   "source": [
    "users_matrics = pickle.load(open('users_matrics.pkl', mode='rb'))\n",
    "print(users_matrics)\n",
    "movie_matrics = pickle.load(open('movie_matrics.pkl', mode='rb'))\n",
    "print(movie_matrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie you watching is：[1401 'Ghosts of Mississippi (1996)' 'Drama']\n",
      "People who like the movie are：[[4673 'M' 35 16]\n",
      " [3095 'F' 25 3]\n",
      " [85 'M' 18 4]\n",
      " [371 'M' 18 4]\n",
      " [2496 'M' 50 1]\n",
      " [2559 'M' 18 10]\n",
      " [451 'M' 56 13]\n",
      " [1069 'M' 25 20]\n",
      " [942 'F' 50 6]\n",
      " [3901 'M' 18 14]\n",
      " [2338 'M' 45 17]\n",
      " [3959 'F' 45 1]\n",
      " [5861 'F' 50 1]\n",
      " [5050 'F' 18 4]\n",
      " [4754 'F' 18 0]\n",
      " [4800 'M' 18 4]\n",
      " [100 'M' 35 17]\n",
      " [2154 'M' 25 12]\n",
      " [2696 'M' 25 7]\n",
      " [3978 'M' 35 13]]\n",
      "Other movies may like：\n",
      "2693\n",
      "[2762 'Sixth Sense, The (1999)' 'Thriller']\n",
      "2502\n",
      "[2571 'Matrix, The (1999)' 'Action|Sci-Fi|Thriller']\n",
      "777\n",
      "[787 'Gate of Heavenly Peace, The (1995)' 'Documentary']\n",
      "2128\n",
      "[2197 'Firelight (1997)' 'Drama']\n",
      "315\n",
      "[318 'Shawshank Redemption, The (1994)' 'Drama']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{315, 777, 2128, 2502, 2693}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_other_favorite_movie(1401, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
